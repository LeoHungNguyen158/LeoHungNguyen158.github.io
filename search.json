[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Analytics, Modeling & Insight Engineering\n\nStrategic, Data-Driven Solutions Across Real-World Projects\nI specialize in translating complex datasets into analytical systems, predictive models, and meaningful insights that support business growth and decision-making.\n\n\n\n\n\n\n\nüç∫ Microbrewery Strategic & Quality Control Analysis\n\n\nOperations optimization project involving Monte Carlo simulations, decision trees, break-even analysis, and linear programming to forecast ROI and improve production planning.\n\nView Full Project\n\n\n\n\nüåä Cruise Market Segmentation & Conjoint Analysis\n\n\nA comprehensive analytics study involving passenger segmentation, K-means clustering, conjoint analysis, and marketing strategy optimization for the Caribbean cruise industry.\n\nView Full Project\n\n\n\n\nüè° Airbnb Market Pricing & Predictive Modeling\n\n\nMachine learning and statistical modeling techniques to predict Airbnb prices, analyze key drivers, and segment property types using regression, PCA, clustering, and classification.\n\nView Full Project\n\n\n\n\nüõí Northwind SQL ‚Üí Python Analytics Pipeline\n\n\nEnd-to-end analytics workflow using SQL (CTEs + window functions), Python data processing, forecasting with ARIMA, and customer segmentation using K-Means clustering.\n\nView Full Project"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "üìÑ Curriculum Vitae\nYou can download my full r√©sum√© below:\nüì• Download Resume (PDF)\n\n\nüéì Education\n\nBoston University ‚Äî Metropolitan College (Boston, MA)\nM.S. in Applied Business Analytics\nExpected January 2026\nRelevant Coursework:\n- Data Mining\n- Cloud Analytics\n- Python & SQL\n- Marketing Analytics\n- Enterprise Risk Analytics\n- Decision-Making & Operations\n\n\n\nUniversity of Technology Sydney (Sydney, Australia)\nMaster of Property Development & Project Management (2019‚Äì2024)\nRelevant Coursework:\n- Advances in Project Management\n- Project Risk & Procurement\n- Quality Management\n\n\n\nüíº Experience\n\nTeaching Assistant ‚Äî AD599 Python & SQL for Business Analytics\nBoston University | Sept 2025 ‚Äì Present\n- Support 70+ graduate students with Python scripting, SQL querying, and data modeling labs\n- Grade assignments and guide students through loops, joins, and analytic logic\n- Assist instructors with project evaluation and course content refinement\n\n\n\nDigital Marketing Director ‚Äî Tin A Co., Ltd\nHo Chi Minh City, Vietnam | Mar 2024 ‚Äì Mar 2025\n- Led international market-entry and marketing strategies across renewable energy, healthcare tech, and consumer sectors\n- Improved targeting accuracy through segmentation\n- Streamlined logistics for 7+ monthly import/export operations\n- Secured 5+ partnerships across Asia, Australia, and North America\n\n\n\nData Analyst ‚Äî Finance Department\nMarriott Bonvoy Renaissance Riverside | Mar 2022 ‚Äì Jul 2023\n- Supported cost modeling and financial forecasting contributing to quarterly revenue uplift\n- Automated 10+ recurring reporting workflows using Excel VBA & PivotTables\n- Improved inventory accuracy by supporting cross-department audit initiatives\n\n\n\nMarketing & Project Development ‚Äî Thang Uy Group\nHo Chi Minh City, Vietnam | Mar 2021 ‚Äì Mar 2022\n- Conducted market and competitor research for EV infrastructure expansion\n- Assisted in investor engagement for early-phase EV initiatives\n- Facilitated multinational partnerships across Singapore, Korea, and Israel\n\n\n\nüõ† Technical Skills\nLanguages: Python, R, SQL\nDatabases: MySQL, SQLite, Google BigQuery\nTools: Power BI, Tableau, RStudio, Jupyter, Excel (VBA, Solver, PivotTables)\nStrengths: Predictive Modeling, Data Cleaning, ETL Automation, Forecasting, Optimization, Visualization"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "I Turn Complex Data Into Clarity, Confidence, and Competitive Advantage\n\nData Analyst ‚Ä¢ Business Analytics ‚Ä¢ Machine Learning ‚Ä¢ Strategy\nTransforming raw data into insights that help organizations make smarter, faster, and more informed decisions.\n\n\n\n\nWelcome to My Portfolio\nThank you for visiting my professional analytics portfolio.\nI‚Äôm Leo Hung Nguyen, a graduate student in Applied Business Analytics at Boston University, specializing in:\n\nPredictive Modeling & Machine Learning\n\nData Engineering & ETL Pipelines\n\nBusiness Intelligence & Decision Science\n\nSQL + Python Analytics Workflows\n\nOperations, Risk, and Market Analysis\n\nAcross my academic and professional journey, I‚Äôve tackled real-world problems in:\n\nHospitality finance\n\nInternational marketing\n\nRenewable energy & EV tech\n\nHealthcare technology\n\nSupply chain & logistics\n\nConsumer behavior analytics\n\nThis site showcases a curated selection of my strongest analytics projects, each combining technical modeling with business impact.\nUse the navigation bar to explore:\n\nAbout My background & experience\n\nProjects Interactive case-study pages\n\nCV Full r√©sum√©\n\nContact Get in touch"
  },
  {
    "objectID": "projects/project_northwind.html",
    "href": "projects/project_northwind.html",
    "title": "Northwind SQL ‚Üí Python Analytics Pipeline",
    "section": "",
    "text": "üõí Northwind SQL ‚Üí Python Analytics Pipeline\n\nData Engineering ‚Ä¢ Forecasting ‚Ä¢ Clustering ‚Ä¢ ETL Automation\nAn end-to-end analytics workflow built with SQL, Python, forecasting models, and customer segmentation techniques using the classic Northwind database.\n\n\n\n\n\nüìå Executive Summary\nThis project demonstrates a complete business analytics pipeline, combining:\n\nAdvanced SQL queries (CTEs, window functions, subqueries)\n\nETL data processing in Python\n\nExploratory Data Analysis (EDA)\n\nARIMA Forecasting for monthly sales\n\nCustomer Clustering (K-Means / RFM)\n\nBusiness insights for inventory, performance, and marketing\n\nThe project replicates a real-world analytics environment, showcasing an analyst‚Äôs ability to work across data extraction, transformation, modeling, and final recommendation delivery.\n\n\n\n\nüîß Methods & Techniques\n\nSQL Engineering\n\nCommon Table Expressions (CTEs)\n\nWindow functions (ROW_NUMBER, RANK, PARTITION BY)\n\nAggregation & joins across multiple tables\n\nPerformance ranking\n\nTime-series SQL transformations\n\n\n\nPython ETL & Analytics\n\nData cleaning & preprocessing\n\nMerging SQL extracts\n\nPandas-based automation\n\nVisual analytics\n\n\n\nForecasting\n\nARIMA model\n\nAIC-based model selection\n\nForecast visualization\n\nSeasonality & trend decomposition\n\n\n\nCustomer Segmentation\n\nRFM scoring\n\nK-means clustering\n\nCluster interpretation & profiling\n\nCustomer lifetime value insights\n\n\n\n\n\n\nüîç Key Insights\n\nüßÆ 1. Employee Sales Performance\nSQL window functions revealed top-performing employees and efficiency gaps across product lines.\n\n\nüì¶ 2. Category-Level Insights\nCTEs showed strong seasonality across top-selling product categories.\n\n\nüìà 3. Sales Forecasting\nARIMA projections indicated steady growth trends, enabling improved inventory and supply planning.\n\n\nüë• 4. Customer Segmentation\nRFM + K-means clustering identified: - High-value repeat customers\n- Seasonal bulk buyers\n- At-risk customers who could be targeted for retention campaigns\n\n\nüí° 5. Strategic Recommendations\n\nImprove targeting for high-value segments\n\nAdjust inventory cycles around forecasted peaks\n\nIncrease visibility for high-margin categories\n\n\n\n\n\n\nüìé Project Files\n\nüìù Phase 1 Report (DOCX)\nüì• Download Phase 1\n\n\nüìò Phase 2 Analysis (PDF)\nüì• Download Phase 2 (Model Output)\n\n\nüé§ Presentation (PPTX)\nüì• Download Final Presentation\n\n\n\n\n\n‚¨Ö Back to Projects"
  },
  {
    "objectID": "projects/files/TeamUrsula_AD654_SemesterProject.html",
    "href": "projects/files/TeamUrsula_AD654_SemesterProject.html",
    "title": "Team Ursula - Semester Project",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\n\n\nData Visualization\n\n\n\nDashboard.png\n\n\nThe bar chart titled as ‚ÄúPassenger Density by Cruise Line‚Äù compares average passenger density (i.e., crowding levels) by cruise line. The results show that cruise lines like Silversea, Regent_Seven_Seas, and Crystal have higher average passenger density, meaning that these lines are relatively more crowded. While other cruise lines like Royal Caribbean, Carnival, Norwegian, MSC, and Orient have lower average passenger density, meaning that these cruise lines offer more space and comfort for each passenger.\nThe bar chart titled as ‚ÄúPassenger Capacity by Cruise Line‚Äù compares the average number of passengers the ship is designed to carry under normal occupancy conditions across different cruise lines. Results suggest that cruise lines like Royal Caribbean, Carnival, and Princess have much greater passenger capacity than other cruise lines, meaning that they can carry way more passengers than others.\nTaken the two graphs together, cruise lines like Royal Caribbean and Carnival balance scale with guest experience, as they operate mega-ships that achieve high total passenger capacity while maintaining relatively moderate passenger density. Their ship designs leverage massive internal volume to offer a better guest experience without sacrificing scale, giving them a competitive edge in the mass-market cruise segment.\nThe plot titled as ‚ÄúTonnage vs Passenger Capacity‚Äù shows a strong positive linear relationship between ship tonnage and passenger capacity, indicating that large ships generally accommodate more guests. Ships significantly below the trend line likely prioritize guest space and luxury. Overall, this visualization provides a foundational overview of ship design efficiency and space utilization across different cruise lines.\nTo make the plot titled as ‚ÄúAverage Age by Cruise Line (Top 5)‚Äù, we picked the five cruise lines that have the oldest ships and compared the average age of their ships. Among the selected cruise lines, ship ages range from approximately 7 to over 47 years. Orient‚Äôs Marco Polo and Cunard‚Äôs Queen Elizabeth II are exceptionally old, with over 40 years of operating history. Meanwhile, Norwegian and Star have relatively newer ships and maintain a more balanced ship age profile, suggesting a gradual modernization strategy. We focused on cruise lines with older ships to target insights into maintenance, guest satisfaction risks, and modernization strategies. As consumer expectations evolve, older ships may face heightened pressure to upgrade or replace ships to stay competitive. On the other hand, lines with a more balanced mix of ship ages may offer both legacy branding and modern experiences.\nBased on our findings, we recommend that Lobster Land Management should prioritize using newer, large-capacity ships to maximize exposure to high-volume, modernized traffic while minimizing potential operational risks. However, it is important to note that the dataset reflects average ship-level statistics and may not capture ship-specific refurbishments or modernization investments. Further, passenger density alone does not fully capture onboard experience factors like design innovation or service quality, so additional qualitative research into individual cruise offerings is suggested.\n\n\nSummary Stats\n\nports = pd.read_csv('caribbean_ports.csv')\n\n\nports.head()\n\n\n    \n\n\n\n\n\n\nport_id\nport_name\ncountry_or_territory\nregion\nport_type\nlatitude\nlongitude\navg_annual_visitors\navg_port_fee_usd\nlocal_attractions_score\navg_customer_satisfaction\nexcursion_variety_index\navg_disembark_rate\navg_shore_spend_per_passenger\nseasonality_score\n\n\n\n\n0\n1\nCozumel\nMexico\nWestern\nPrivate\n23.7406\n-66.7748\n187848\n13.75\n6\n8.23\n2\n0.82\n175.22\n0.99\n\n\n1\n2\nCosta Maya\nMexico\nWestern\nEco/Nature\n13.4943\n-65.7182\n667075\n13.77\n3\n9.74\n10\n0.52\n100.07\n0.78\n\n\n2\n3\nProgreso\nMexico\nWestern\nMajor\n18.9991\n-83.1489\n177948\n12.11\n9\n8.78\n3\n0.69\n156.40\n0.44\n\n\n3\n4\nBelize City\nBelize\nWestern\nPrivate\n20.3673\n-76.0384\n452690\n4.53\n4\n12.50\n1\n0.81\n157.05\n0.18\n\n\n4\n5\nRoat√°n\nHonduras\nWestern\nPrivate\n10.8129\n-82.1033\n549046\n17.20\n1\n6.39\n8\n0.75\n43.05\n0.80\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nports.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50 entries, 0 to 49\nData columns (total 15 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   port_id                        50 non-null     int64  \n 1   port_name                      50 non-null     object \n 2   country_or_territory           50 non-null     object \n 3   region                         50 non-null     object \n 4   port_type                      50 non-null     object \n 5   latitude                       50 non-null     float64\n 6   longitude                      50 non-null     float64\n 7   avg_annual_visitors            50 non-null     int64  \n 8   avg_port_fee_usd               50 non-null     float64\n 9   local_attractions_score        50 non-null     int64  \n 10  avg_customer_satisfaction      50 non-null     float64\n 11  excursion_variety_index        50 non-null     int64  \n 12  avg_disembark_rate             50 non-null     float64\n 13  avg_shore_spend_per_passenger  50 non-null     float64\n 14  seasonality_score              50 non-null     float64\ndtypes: float64(7), int64(4), object(4)\nmemory usage: 6.0+ KB\n\n\nData Type\nCategorical Variables: port_id, port_name, country_or_territory, region, port_type\nNumerical Variables: latitude, longitude, avg_annual_visitors, avg_port_fee_usd, local_attraction_score, avg_customer_satisfaction, excursion_variety_index, avg_disembark_rate, avg_shore_spend_per_passenger, seasonality_score\n\nports.describe()\n\n\n    \n\n\n\n\n\n\nport_id\nlatitude\nlongitude\navg_annual_visitors\navg_port_fee_usd\nlocal_attractions_score\navg_customer_satisfaction\nexcursion_variety_index\navg_disembark_rate\navg_shore_spend_per_passenger\nseasonality_score\n\n\n\n\ncount\n50.00000\n50.000000\n50.000000\n5.000000e+01\n50.000000\n50.000000\n50.00000\n50.000000\n50.000000\n50.000000\n50.000000\n\n\nmean\n25.50000\n18.470906\n-72.804902\n7.061286e+05\n10.706200\n4.440000\n8.19820\n5.980000\n0.764000\n112.894200\n0.566200\n\n\nstd\n14.57738\n5.560868\n7.250157\n4.517732e+05\n5.430777\n2.865417\n1.27086\n3.040475\n0.165603\n58.994124\n0.284461\n\n\nmin\n1.00000\n10.096600\n-84.364500\n7.195900e+04\n-3.500000\n1.000000\n6.12000\n1.000000\n0.510000\n-45.000000\n0.110000\n\n\n25%\n13.25000\n13.441650\n-79.151925\n2.761048e+05\n5.802500\n2.250000\n7.37250\n4.000000\n0.640000\n56.592500\n0.350000\n\n\n50%\n25.50000\n18.832350\n-72.470400\n6.993720e+05\n12.055000\n4.000000\n8.27000\n6.000000\n0.790000\n117.295000\n0.570000\n\n\n75%\n37.75000\n23.696650\n-66.013100\n1.065037e+06\n14.460000\n6.000000\n9.05000\n9.000000\n0.897500\n163.442500\n0.795000\n\n\nmax\n50.00000\n27.270500\n-61.757600\n1.492646e+06\n18.920000\n15.000000\n12.50000\n10.000000\n1.200000\n197.660000\n0.990000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\nImpossible Values\navg_port_fee_usd: Minimum is -4, but the values of this variable should be greater than 0.\nlocal_attractions_score: Maximum is 15, but scores should range from 1 to 10.\navg_customer_satisfaction: Maximum is 12, but the valid scale is 1-10.\navg_shore_spend_per_passenger: Minimum is -45, but the values of this variable should be greater than 0.\n\nimpossible_values = {\n    \"avg_port_fee_usd\": ports[\"avg_port_fee_usd\"] &lt;= 0,\n    \"local_attractions_score\": ~ports[\"local_attractions_score\"].between(1, 10),\n    \"avg_customer_satisfaction\": ~ports[\"avg_customer_satisfaction\"].between(1, 10),\n    \"avg_shore_spend_per_passenger\": ports[\"avg_shore_spend_per_passenger\"] &lt;= 0\n}\n\nimpossible_counts = {var: condition.sum() for var, condition in impossible_values.items()}\npd.DataFrame.from_dict(impossible_counts, orient='index', columns=[\"Impossible Value Count\"])\n\n\n    \n\n\n\n\n\n\nImpossible Value Count\n\n\n\n\navg_port_fee_usd\n1\n\n\nlocal_attractions_score\n1\n\n\navg_customer_satisfaction\n1\n\n\navg_shore_spend_per_passenger\n1\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nports = ports.drop(ports[\n    (ports['avg_port_fee_usd'] &lt;= 0) |\n    (ports['local_attractions_score'] &lt; 1) | (ports['local_attractions_score'] &gt; 10) |\n    (ports['avg_customer_satisfaction'] &lt; 1) | (ports['avg_customer_satisfaction'] &gt; 10) |\n    (ports['avg_shore_spend_per_passenger'] &lt;= 0)\n].index)\n\n\nports.isnull().sum()\n\n\n\n\n\n\n\n\n0\n\n\n\n\nport_id\n0\n\n\nport_name\n0\n\n\ncountry_or_territory\n0\n\n\nregion\n0\n\n\nport_type\n0\n\n\nlatitude\n0\n\n\nlongitude\n0\n\n\navg_annual_visitors\n0\n\n\navg_port_fee_usd\n0\n\n\nlocal_attractions_score\n0\n\n\navg_customer_satisfaction\n0\n\n\nexcursion_variety_index\n0\n\n\navg_disembark_rate\n0\n\n\navg_shore_spend_per_passenger\n0\n\n\nseasonality_score\n0\n\n\n\n\ndtype: int64\n\n\nMissing Value\nThe results above suggest that there is no missing value in the dataset.\nAverage Annual Visitors by Port Name (Top 5)\n\nvisitors_by_port = ports.groupby(\"port_name\")[\"avg_annual_visitors\"].mean().sort_values(ascending=False).head(5)\nvisitors_by_port\n\n\n\n\n\n\n\n\navg_annual_visitors\n\n\nport_name\n\n\n\n\n\nPuerto Plata\n1492646.0\n\n\nPonce\n1479626.0\n\n\nSanto Domingo\n1450804.0\n\n\nPrincess Cays\n1434250.0\n\n\nSt. Maarten\n1413453.0\n\n\n\n\ndtype: float64\n\n\n\nfrom matplotlib.ticker import FuncFormatter\n\nvisitors_by_port = visitors_by_port.reset_index()\n\nplt.figure(figsize=(10, 6))\nalpha = sns.barplot(data=visitors_by_port, x=\"port_name\", y=\"avg_annual_visitors\", color=\"skyblue\")\nplt.title(\"Top 5 Ports by Average Annual Visitors\")\nplt.xlabel(\"Port Name\")\nplt.ylabel(\"Average Annual Visitors\")\nplt.ylim(1_200_000, 1_520_000)\n\nalpha.yaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{int(x):,}'))\nfor bar in alpha.patches:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, height + 5000, f'{int(height):,}',\n             ha='center', va='bottom', fontsize=10)\n\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAverage Customer Satisfaction by Region\n\nsatisfaction = ports.groupby(\"region\")[\"avg_customer_satisfaction\"].mean().sort_values(ascending=False)\nsatisfaction\n\n\n\n\n\n\n\n\navg_customer_satisfaction\n\n\nregion\n\n\n\n\n\nBahamas\n8.297143\n\n\nEastern\n8.188571\n\n\nSouthern\n7.950909\n\n\nWestern\n7.845714\n\n\n\n\ndtype: float64\n\n\n\nsatisfaction = satisfaction.reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\nbeta = sns.barplot(data=satisfaction, x=\"region\", y=\"avg_customer_satisfaction\", color=\"powderblue\")\nplt.title(\"Average Customer Satisfaction by Region\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Average Customer Satisfaction\")\nplt.ylim(7,8.4)\n\nfor bar in beta.patches:\n    height = bar.get_height()\n    beta.text(bar.get_x() + bar.get_width()/2, height + 0.02, f'{height:.2f}',\n            ha='center', va='bottom', fontsize=10)\n\nplt.show()\n\n\n\n\n\n\n\n\nAverage Ashore Spending by Port Type\n\nspending = ports.groupby(\"port_type\")[\"avg_shore_spend_per_passenger\"].mean().sort_values(ascending=False)\nspending\n\n\n\n\n\n\n\n\navg_shore_spend_per_passenger\n\n\nport_type\n\n\n\n\n\nMajor\n120.343750\n\n\nBoutique\n119.862727\n\n\nEco/Nature\n117.466875\n\n\nPrivate\n99.833636\n\n\n\n\ndtype: float64\n\n\n\nspending = spending.reset_index()\n\nplt.figure(figsize=(10, 6))\ngamma = sns.barplot(data=spending, x=\"port_type\", y=\"avg_shore_spend_per_passenger\", color=\"steelblue\")\nplt.title(\"Average Ashore Spending by Port Type ($)\")\nplt.xlabel(\"Port Type\")\nplt.ylabel(\"Average Spending per Passenger ($)\")\n\nfor bar in gamma.patches:\n    height = bar.get_height()\n    gamma.text(bar.get_x() + bar.get_width()/2, height + 1, f\"{height:,.2f}\", ha='center', va='bottom', fontsize=10)\n\n\n\n\n\n\n\n\nAverage Shore Excursion by Region\n\nshore_excursion = ports.groupby(\"region\")[\"excursion_variety_index\"].mean().sort_values(ascending=False)\nshore_excursion\n\n\n\n\n\n\n\n\nexcursion_variety_index\n\n\nregion\n\n\n\n\n\nBahamas\n7.000000\n\n\nEastern\n6.571429\n\n\nWestern\n5.714286\n\n\nSouthern\n5.181818\n\n\n\n\ndtype: float64\n\n\n\nshore_excursion = shore_excursion.reset_index()\n\nplt.figure(figsize=(10, 6))\nsns.set_style(\"whitegrid\")\ndelta = sns.barplot(data=shore_excursion, x=\"region\", y=\"excursion_variety_index\", color=\"cornflowerblue\")\nplt.title(\"Shore Excursion Variety by Region\")\nplt.xlabel(\"Region\")\nplt.ylabel(\"Excursion Variety Index\")\n\nfor bar in delta.patches:\n    height = bar.get_height()\n    delta.text(bar.get_x() + bar.get_width()/2, height + 0.1, f\"{height:.2f}\", ha='center', va='bottom', fontsize=10)\n\nplt.show()\n\n\n\n\n\n\n\n\nFindings\nFrom the visual analysis of Caribbean cruise port data, several actionable insights emerge. First, three of the top five ports by annual visitor volume‚ÄîPuerto Plata, Ponce, and St.¬†Maarten‚Äîare located in the Eastern Caribbean, indicating this sub-region draws a consistently high volume of cruise travelers. This aligns with the second finding: the Eastern Caribbean ranks second in both customer satisfaction and shore excursion variety, just behind the Bahamas, suggesting that this region not only attracts high traffic but also delivers satisfying and diverse passenger experiences.\nAdditionally, when analyzing average ashore spending by port type, Major and Boutique ports show the highest passenger spending, with only a marginal difference between them. This suggests that both high-traffic infrastructure and more curated, upscale experiences appeal to travelers and lead to higher onboard-to-shore revenue conversion.\nFor Lobster Land, which may be exploring regional expansion, vendor partnerships, or targeted marketing, these patterns suggest strong opportunities in the Eastern Caribbean and the Bahamas, especially at Major and Boutique ports, where both traffic and spending levels are high. These areas may offer the best return on investment for experiential offerings, pop-up activations, or new retail ventures.\n\n\nSegmentation and Targeting\nJean & Leo\n\nports = pd.read_csv('caribbean_ports.csv')\nprint(ports.head())\n\n   port_id    port_name country_or_territory   region   port_type  latitude  \\\n0        1      Cozumel               Mexico  Western     Private   23.7406   \n1        2   Costa Maya               Mexico  Western  Eco/Nature   13.4943   \n2        3     Progreso               Mexico  Western       Major   18.9991   \n3        4  Belize City               Belize  Western     Private   20.3673   \n4        5       Roat√°n             Honduras  Western     Private   10.8129   \n\n   longitude  avg_annual_visitors  avg_port_fee_usd  local_attractions_score  \\\n0   -66.7748               187848             13.75                        6   \n1   -65.7182               667075             13.77                        3   \n2   -83.1489               177948             12.11                        9   \n3   -76.0384               452690              4.53                        4   \n4   -82.1033               549046             17.20                        1   \n\n   avg_customer_satisfaction  excursion_variety_index  avg_disembark_rate  \\\n0                       8.23                        2                0.82   \n1                       9.74                       10                0.52   \n2                       8.78                        3                0.69   \n3                      12.50                        1                0.81   \n4                       6.39                        8                0.75   \n\n   avg_shore_spend_per_passenger  seasonality_score  \n0                         175.22               0.99  \n1                         100.07               0.78  \n2                         156.40               0.44  \n3                         157.05               0.18  \n4                          43.05               0.80  \n\n\n\nmissing_values = ports.isnull().sum()\nprint(missing_values)\n\nport_id                          0\nport_name                        0\ncountry_or_territory             0\nregion                           0\nport_type                        0\nlatitude                         0\nlongitude                        0\navg_annual_visitors              0\navg_port_fee_usd                 0\nlocal_attractions_score          0\navg_customer_satisfaction        0\nexcursion_variety_index          0\navg_disembark_rate               0\navg_shore_spend_per_passenger    0\nseasonality_score                0\ndtype: int64\n\n\n\n#Using only numeric variables for clustering\nnumeric_cols = [\n    'avg_annual_visitors',\n    'avg_port_fee_usd',\n    'local_attractions_score',\n    'avg_customer_satisfaction',\n    'excursion_variety_index',\n    'avg_disembark_rate',\n    'avg_shore_spend_per_passenger',\n    'seasonality_score'\n]\n\nX = ports[numeric_cols].dropna()\n\n\n#Standardizing data to make sure they're on the same scale\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n\n#Kmeans to identify number of clusters\ninertia = []\nk_range = range(2, 10)\nfor k in k_range:\n    km = KMeans(n_clusters=k, random_state=654)\n    km.fit(X_scaled)\n    inertia.append(km.inertia_)\n\nplt.plot(k_range, inertia, marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.title('Elbow Method for Optimal k')\nplt.show()\n\n\n\n\n\n\n\n\n\n#Assigning each port to a cluster\nkmeans = KMeans(n_clusters=3, random_state=42)\nports['cluster'] = kmeans.fit_predict(X_scaled)\n\n\ncluster_counts = ports['cluster'].value_counts()\nprint(cluster_counts)\n\ncluster\n1    21\n0    18\n2    11\nName: count, dtype: int64\n\n\nWe chose to segment the ports into three clusters to distribute the ports evenly across groups. Segmentation over three clusters resulted in at least one minority cluster with a significantly smaller number of ports, which could have affected strategic decision-making. Considering that this is Lobster Land‚Äôs first venture into the cruise business, we wanted a balanced segmentation that offers a comprehensive view across different types of ports.\nBy focusing on three clusters, we can more effectively align port profiles with specific business strategies and abilities. We also preferred to concentrate on ports with proven popularity and strong visitor traffic, rather than investing heavily in less preferred or more experimental destinations at this early stage. This approach allows Lobster Land to build a strong foundation in the cruise market while still leaving room for future innovation and expansion once brand credibility and operational experience grow.\n\n#Visualizations to help communicate information from the model\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=ports, x='avg_annual_visitors', y='avg_shore_spend_per_passenger', hue='cluster', palette='Set2')\nplt.title('Annual Visitors vs Shore Spend by Cluster')\nplt.xlabel('Avg Annual Visitors')\nplt.ylabel('Avg Shore Spend per Passenger')\nplt.legend(title='Cluster')\nplt.grid(False)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis scatterplot explores the potential relationship between average annual visitors and shore spend per passenger across clusters. While there is no clear linear trend within any individual cluster, a rough differentiation can be observed:\n\nCluster 1 ports tend to attract fewer visitors but generate higher average spending per passenger.\nCluster 0 ports typically handle larger visitor volumes but yield lower per-passenger spending.\n\nThere‚Äôs also considerable overlap between clusters, suggesting that other variables ‚Äî such as customer satisfaction, excursion variety, or seasonality ‚Äî likely played a stronger role in shaping the segmentation results.\n\nplt.figure(figsize=(6, 5))\nsns.boxplot(data=ports, x='cluster', y='avg_customer_satisfaction', palette='Set3')\nplt.title('Customer Satisfaction by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Avg Customer Satisfaction')\nplt.tight_layout();\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=ports, x='cluster', y='avg_customer_satisfaction', palette='Set3')\n\n\n\n\n\n\n\n\n\nThis boxplot displays the distribution of average customer satisfaction scores across the three clusters.\nCluster 1 exhibits the highest overall satisfaction, although it also has the widest interquartile range, indicating more variability among ports in that group. In contrast, Cluster 0 shows the lowest satisfaction but a narrower IQR, suggesting more consistency in traveler feedback.\nSince the satisfaction scale ranges from 0 to 10, even small differences can meaningfully impact passenger experience. Cluster 2 falls in a mid-to-high satisfaction band and overlaps slightly with the other two, making it more heterogeneous.\nNotably, Cluster 2 includes one extreme outlier with a score above 12, which is likely a data entry error and should be flagged for correction.\n\nplt.figure(figsize=(7, 5))\nsns.histplot(data=ports, x='seasonality_score', hue='cluster', element='step', stat='density', common_norm=False, palette='Set3')\nplt.title('Distribution of Seasonality Score by Cluster')\nplt.xlabel('Seasonality Score')\nplt.ylabel('Density')\nplt.grid(False)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis histogram displays the distribution of seasonality scores across the three clusters, offering insight into how seasonal fluctuations vary between port groups.\n\nCluster 1 ports show high seasonality, with the majority concentrated in the upper range (0.8‚Äì1.0). These ports are more sensitive to time-of-year fluctuations and may require flexible itinerary planning.\nCluster 0 has a more even distribution across low to moderate seasonality levels, indicating more operational flexibility.\nCluster 2 exhibits low seasonality, with most ports concentrated in the 0.1‚Äì0.4 range ‚Äî making them attractive for year-round cruising.\n\nThe limited overlap between the clusters suggests that seasonality is a strong segmenting variable in this analysis.\n\n# Create seasonality categories\nports['seasonality_category'] = pd.cut(ports['seasonality_score'],\n                                       bins=[0, 0.33, 0.66, 1],\n                                       labels=['Low', 'Medium', 'High'])\n\nplt.figure(figsize=(8,6))\nsns.boxplot(data=ports, x='seasonality_category', y='avg_annual_visitors', palette='Set3')\nplt.title('Avg Annual Visitors by Seasonality Category')\nplt.xlabel('Seasonality Category')\nplt.ylabel('Average Annual Visitors')\nplt.tight_layout()\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.boxplot(data=ports, x='seasonality_category', y='avg_annual_visitors', palette='Set3')\n\n\n\n\n\n\n\n\n\n\navg_excursions = ports.groupby('cluster')['excursion_variety_index'].mean().sort_index()\n\nplt.figure(figsize=(6, 4))\nsns.barplot(x=avg_excursions.index, y=avg_excursions.values, palette='Set3')\nplt.title('Avg Excursion Variety Index by Cluster')\nplt.xlabel('Cluster')\nplt.ylabel('Avg Excursion Variety Index')\nplt.tight_layout()\nplt.show()\n\nFutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  sns.barplot(x=avg_excursions.index, y=avg_excursions.values, palette='Set3')\n\n\n\n\n\n\n\n\n\nThis bar plot compares the average excursion variety index across clusters. Ports in Cluster 2 clearly stand out, offering the highest variety of shore excursions on average. In contrast, Clusters 0 and 1 provide similar, but noticeably lower, levels of excursion diversity.\nThese results suggest that Cluster 2 ports may appeal more to adventure-seeking travelers or those who value diverse experiences. These ports could be excellent additions to itineraries targeting active or exploratory customer segments.\n\nprint(ports.head())\nprint(ports['cluster'].unique())\n\n   port_id    port_name country_or_territory   region   port_type  latitude  \\\n0        1      Cozumel               Mexico  Western     Private   23.7406   \n1        2   Costa Maya               Mexico  Western  Eco/Nature   13.4943   \n2        3     Progreso               Mexico  Western       Major   18.9991   \n3        4  Belize City               Belize  Western     Private   20.3673   \n4        5       Roat√°n             Honduras  Western     Private   10.8129   \n\n   longitude  avg_annual_visitors  avg_port_fee_usd  local_attractions_score  \\\n0   -66.7748               187848             13.75                        6   \n1   -65.7182               667075             13.77                        3   \n2   -83.1489               177948             12.11                        9   \n3   -76.0384               452690              4.53                        4   \n4   -82.1033               549046             17.20                        1   \n\n   avg_customer_satisfaction  excursion_variety_index  avg_disembark_rate  \\\n0                       8.23                        2                0.82   \n1                       9.74                       10                0.52   \n2                       8.78                        3                0.69   \n3                      12.50                        1                0.81   \n4                       6.39                        8                0.75   \n\n   avg_shore_spend_per_passenger  seasonality_score  cluster  \\\n0                         175.22               0.99        1   \n1                         100.07               0.78        1   \n2                         156.40               0.44        1   \n3                         157.05               0.18        2   \n4                          43.05               0.80        0   \n\n  seasonality_category  \n0                 High  \n1                 High  \n2               Medium  \n3                  Low  \n4                 High  \n[1 2 0]\n\n\n\n#Renaming clusters to use in visualization\ncluster_names = {\n    0: 'Popular Tourist Ports',\n    1: 'Premium Experience Ports',\n    2: 'Niche Interest Ports'}\n\nports['cluster_name_new'] = ports['cluster'].map(cluster_names)\n\nCluster Names\n\nCluster 0 = Popular Tourist Ports:\n\nThis cluster includes primarily Private and Major ports, heavily located in the Western Caribbean and Southern regions. These ports welcome a high number of visitors, and disembarkation rates are consistently high, often above 0.8.\nMoreover, their port fees range from mid to high, and customer satisfaction is moderate to good with noticeable variance. There‚Äôs also a broad range in shore spend, from as low as 27 dollars to as high as 168 dollars, indicating mixed consumer reactions. These are well-frequented, accessible ports with broad appeal ‚Äî ideal for high-volume, family-friendly itineraries.\n\nCluster 1 = Premium Experience Ports:\n\nPorts in this cluster span various types (Eco/Nature, Major, Boutique) and are mostly located in the Eastern and Southern Caribbean. This group stands out with very high customer satisfaction (often above 9.0), strong shore spend levels (frequently 150+ dollars), and moderate to high excursion variety.\nWith their healthy disembarkation rates, and port fees are among the highest observed in the dataset. These ports are ideal for guests seeking quality, variety, and immersive experiences, and are well-positioned for premium cruise lines and affluent traveler segments.\n\nCluster 2 = Niche Interest Ports\n\nThis is the smallest cluster, and includes a mix of Private, Boutique, and Eco/Nature ports spread across various regions. Visitor volume is generally low to moderate, port fees are on the lower end, and attraction scores are often minimal (many below 3).\nDespite this, ports here often exhibit high disembarkation rates and above-average satisfaction, suggesting guests who do visit tend to enjoy the experience. Some entries have very low shore spend, while others peak over $150 ‚Äî indicating polarizing guest behavior. This cluster is ideal for targeting adventurers, niche travelers, or off-the-beaten-path excursions with focused marketing.\n\nsummary_df = pd.DataFrame({\n    \"Cluster Name\": [\n        \"Popular Tourist Ports\",\n        \"Premium Experience Ports\",\n        \"Niche Interest Ports\"\n    ],\n    \"Avg Visitors\": [\"~1.1 million\", \"~520,000\", \"~350,000\"],\n    \"Avg Shore Spend\": [\"$77\", \"$160+\", \"$90\"],\n    \"Avg Satisfaction\": [7.6, 8.4, 8.9],\n    \"Key Traits\": [\n        \"High volume, moderate satisfaction\",\n        \"High-end spenders, luxury positioning\",\n        \"Small-scale, highly satisfied, diverse\"\n    ]\n})\n\nsummary_df.style.set_table_styles([\n    {'selector': 'th', 'props': [('text-align', 'left')]},\n    {'selector': 'td', 'props': [('text-align', 'left')]}\n]).set_properties(**{'font-size': '14px'})\n\n\n\n\n\n\n¬†\nCluster Name\nAvg Visitors\nAvg Shore Spend\nAvg Satisfaction\nKey Traits\n\n\n\n\n0\nPopular Tourist Ports\n~1.1 million\n$77\n7.600000\nHigh volume, moderate satisfaction\n\n\n1\nPremium Experience Ports\n~520,000\n$160+\n8.400000\nHigh-end spenders, luxury positioning\n\n\n2\nNiche Interest Ports\n~350,000\n$90\n8.900000\nSmall-scale, highly satisfied, diverse\n\n\n\n\n\n\n#Change colours\n# Prepare and scale the data\nX = ports[numeric_cols].dropna()\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply KMeans\nkmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\nports['cluster'] = kmeans.fit_predict(X_scaled)\n\n# Group and average using renamed clusters\ncluster_means_named = ports.groupby('cluster_name_new')[numeric_cols].mean().round(2)\n\n# Plot heatmap with named clusters\nplt.figure(figsize=(10, 6))\nsns.heatmap(cluster_means_named, annot=True, cmap='YlGnBu')\nplt.title('Cluster Centers (Feature Means)')\nplt.ylabel('Cluster Name')\nplt.xlabel('Feature')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe heatmap displays the average values of key numeric features across the three identified port clusters, offering a clear picture of each group‚Äôs operational and experiential profile. These values serve as ‚Äúfingerprints‚Äù for each cluster, allowing Lobster Land to differentiate port types not just by geography, but by visitor behavior and economic potential.\nNiche Interest Ports stand out for their lower average annual visitors, around 350,000, and the lowest port fees among all clusters. While these ports are smaller in scale and have relatively modest local attraction scores (3.3), they deliver the highest average customer satisfaction (8.9) and the richest excursion variety index (7.9). Despite their niche positioning, passengers spend a respectable 90 dollars per person on shore, and the seasonality score is notably low at 0.36, suggesting these ports may offer a more stable year-round experience. This cluster likely appeals to more adventurous or experience-driven travelers who value unique, less crowded destinations and diverse activity options.\nIn contrast, Popular Tourist Ports are characterized by the highest average number of annual visitors‚Äîaround 1.1 million‚Äîindicating that these ports serve as high-volume, mainstream destinations. Port fees are moderately high at 12 dollars, and while customer satisfaction (7.6) and excursion variety (5.4) lag behind the other clusters, the disembark rate remains strong at 0.74. The average shore spend per passenger is approximately 77 dollars, and seasonality is moderate at 0.49. These ports reflect the classic Caribbean cruise experience‚Äîefficient, familiar, and accessible to large numbers of travelers. While they may lack exclusivity or personalized appeal, they are ideal for itineraries prioritizing scale and convenience.\nMeanwhile, Premium Experience Ports represent the most aligned destinations for advancing Lobster Land‚Äôs identity as a premium, experience-driven cruise brand. With mid-range visitor volumes ( approx 520,000), these ports achieve a balanced profile: the highest port fees (13 dollars), the best local attraction scores (6.0), and very strong customer satisfaction (8.4). Notably, passengers in this cluster spend over $160 per person while on shore‚Äîthe highest among all clusters‚Äîindicating strong economic potential. Excursion variety is moderate (5.5), and seasonality is relatively high (0.74), meaning these ports may be better suited for seasonal or targeted campaigns. Together, these metrics position this cluster as ideal for curated, upscale cruise experiences designed to attract discerning, higher-spending customers.\nThese visual insights set the foundation for a targeted marketing strategy that aligns port characteristics with customer preferences and Lobster Land‚Äôs branding goals.\nTargeted Marketing Strategy and Strategic Prioritization Based on Port Segmentation\nTo support Lobster Land‚Äôs exploration of a new luxury cruise line, The Lobster Coast Voyage, we conducted a clustering analysis using K-Means to segment Caribbean cruise ports based on operational and experiential characteristics. After exploring a range of cluster numbers and evaluating the balance between interpretability and differentiation, we selected a 3-cluster solution. This model provided meaningful distinctions among ports without overcomplicating the segmentation, ensuring actionable insights for targeted marketing and itinerary planning.\nEach cluster identified through the model offers a distinct profile, enabling tailored marketing strategies and operational focus.\n\nThe first segment, labeled Popular Tourist Ports, comprises high-volume destinations that attract over one million visitors annually on average. These ports tend to maintain moderate-to-high port fees and exhibit strong disembarkation rates, yet offer only average levels of customer satisfaction and excursion variety. These characteristics suggest an appeal to mass-market consumers, including families, first-time cruisers, and budget-conscious travelers seeking accessible, mainstream Caribbean experiences. From a business perspective, these ports should be included in core itineraries aimed at maintaining volume, especially during peak seasons. However, a key tradeoff is that these ports generally yield lower per-passenger revenue and are less effective in building long-term brand loyalty.\nThe second cluster, which we termed Premium Experience Ports, demonstrates the strongest value proposition. Ports in this segment achieve the highest average shore-side spending (over 160 Dollars per passenger), alongside consistently strong scores in satisfaction and attraction quality. Visitor volume is moderate, suggesting a balance between exclusivity and reach. These ports align well with affluent consumers, such as couples, loyal cruisers, and experience-driven travelers who are willing to pay more for quality, curated excursions. Given these characteristics, Lobster Land should prioritize this cluster as the centerpiece of its new luxury cruise offering. The main tradeoff, however, lies in seasonality: these ports display higher variability across the year, which would require dynamic scheduling, pricing flexibility, and potentially more marketing support to smooth demand during off-peak periods.\nThe final cluster, referred to as Niche Interest Ports, is composed of smaller, less trafficked destinations that nonetheless exhibit the highest customer satisfaction and excursion variety. These ports tend to have the lowest port fees and attraction scores but are valued for their authenticity, uniqueness, and appeal to adventurous or specialty-travel segments, such as eco-tourists or cultural explorers. With a lower average visitor count (around 350,000), this group may be less scalable but offers distinct branding opportunities. These ports allow Lobster Land to innovate around themed voyages and boutique experiences, offering distinction from mainstream cruise itineraries. The tradeoff is that these ports may yield inconsistent revenue performance and require additional logistical planning due to dispersed geography and infrastructure variability.\n\nIn summary, Lobster Land‚Äôs targeted marketing strategy should be anchored around Premium Experience Ports, which align most directly with the company‚Äôs luxury ambitions and revenue goals. Popular Tourist Ports serve as reliable volume-drivers, ideal for standard or high-capacity sailings. Niche Interest Ports, while less predictable in terms of margin, offer an opportunity for innovation, differentiation, and deeper engagement with specialized consumer audiences. By leveraging the strengths of each cluster appropriately, Lobster Land can design itineraries that are both operationally efficient and strategically aligned with evolving market demands.\n\n\nForecasting Earnings Per Share\nLoading the financial for both NHLC and CCL into the environment, converting it into time series data and performing EDA\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nNHLC_df = pd.read_excel('Norwegian_financials.xlsx')\nCCL_df = pd.read_excel('Carnival_Corporation_financials .xlsx')\n\n\nNHLC_df.columns = NHLC_df.columns.str.strip()\nCCL_df.columns = CCL_df.columns.str.strip()\n\n\nNHLC_df.head()\n\n\n    \n\n\n\n\n\n\nYear\nEPS\nNet Income (Millions USD)\nShares Outstanding\nRevenue (Millions USD)\n\n\n\n\n0\n2024\n2.09\n910\n515\n9480\n\n\n1\n2023\n0.39\n166\n427\n8550\n\n\n2\n2022\n-5.41\n-2270\n420\n4844\n\n\n3\n2021\n-12.33\n-4507\n365\n648\n\n\n4\n2020\n-15.75\n-4013\n255\n1280\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nCCL_df.head()\n\n\n    \n\n\n\n\n\n\nYear\nEPS\nNet Income (Millions USD)\nShares Outstanding\nRevenue (Millions USD)\n\n\n\n\n0\n2024\n1.44\n1916\n1398\n25021\n\n\n1\n2023\n-0.06\n-74\n1262\n21593\n\n\n2\n2022\n-5.16\n-6093\n1180\n12168\n\n\n3\n2021\n-8.46\n-9501\n1123\n1908\n\n\n4\n2020\n-13.20\n-10236\n775\n5595\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\nPlotting the line graph to understand if there is a trend or seasonal effect or any major fluctuations in EPS that we need to be aware of.\nNorwegian Cruise Lines plot\n\nplt.figure(figsize=(10, 6))\nplt.plot(NHLC_df['Year'], NHLC_df['EPS'], marker='o', linestyle='-')\nplt.title('Norwegian Cruise Lines EPS Over Time')\nplt.xlabel('Year')\nplt.ylabel('EPS')\nplt.axhline(y = NHLC_df['EPS'].mean(), color = 'red', linestyle = '--')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFrom the plot it is clear that the EPS dropped significantly in 2020 and it can be attributed completely to Covid-19 as travel was banned all over the world and the company was out of operations for over 8 months. However, what is interesting to see is that NHLC experienced immediately after they resumed operations. NHLC had specifically laid out strategic plans, infrastructure development and cost management, also most importantly focused on debt reduction that was accumulated during the shutdown period. The specific plans will be discussed in details after forecasting to combine quantitative analysis with qualitative to further analyze the validity of forecast numbers.\nCarnival Corporation Ltd.¬†plot\n\nplt.figure(figsize=(10, 6))\nplt.plot(CCL_df['Year'], CCL_df['EPS'], marker = 'o', linestyle='-')\nplt.title('Carnival Corporation Ltd. EPS Over Time')\nplt.xlabel('Year')\nplt.ylabel('EPS')\nplt.axhline(y = CCL_df['EPS'].mean(), color = 'red', linestyle = '--')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nCarnival Corporation as expected experienced an identical downfall as Norwegian cruise lines in 2020 and experienced a surplus growth immediately after, the only difference here is that visually the rise seems slightly subdued than what NHLC has. As NHLC planned and executed several recovery efforts after Covid, Carnival also followed on the same lines as they introduced fleet optimization and expansion, brand consolidation and most importantly attracting back guests with enhanced experience and pricing strategy. Similar to NHLC, we will further elaborate these initiatives as part of the qualitative analysis of the forecast.\nPerforming Double Exponential Smoothing: Holt‚Äôs Linear Method for NHLC and CCL EPS forecast for 2025.\nThe reason that Double Exponential Smoothing (Holt‚Äôs method) is choosen for forecasting in this case for both the companies because it works well with data that has trend but no seasonality. Both the companies have a steep slope in 2020 and then gain momentum from there on which appears to be linear for both. Hence we can conclude that the trend is additive as data appears to be linear.\nNHLC Forecast\n\nNHLC_df['Year'] = pd.to_datetime(NHLC_df['Year'], format='%Y') + pd.offsets.YearEnd(0)\nNHLC_df.set_index('Year', inplace=True)\n\n\nNHLC_eps = NHLC_df['EPS']\nNHLC_eps.sort_index(inplace=True)\nNHLC_eps\n\n\n\n\n\n\n\n\nEPS\n\n\nYear\n\n\n\n\n\n2010-12-31\n0.13\n\n\n2011-12-31\n0.71\n\n\n2012-12-31\n0.95\n\n\n2013-12-31\n0.50\n\n\n2014-12-31\n1.64\n\n\n2015-12-31\n1.89\n\n\n2016-12-31\n2.79\n\n\n2017-12-31\n3.33\n\n\n2018-12-31\n4.28\n\n\n2019-12-31\n4.33\n\n\n2020-12-31\n-15.75\n\n\n2021-12-31\n-12.33\n\n\n2022-12-31\n-5.41\n\n\n2023-12-31\n0.39\n\n\n2024-12-31\n2.09\n\n\n\n\ndtype: float64\n\n\nGenerating model with manually set parameters for smoothing and initial level\n\nfrom statsmodels.tsa.api import Holt\n\nNHLC_model_known = Holt(NHLC_eps, initialization_method = 'known', initial_level = 0.13,\n                  initial_trend = -0.70, exponential = False)\nNHLC_model_known_result = NHLC_model_known.fit(smoothing_level = 0.7, smoothing_trend = 0.3,\n                                               optimized = False)\nNHLC_model_known_result.summary()\n\n/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-DEC will be used.\n  self._init_dates(dates, freq)\n\n\n\nHolt Model Results\n\n\nDep. Variable:\nEPS\nNo. Observations:\n15\n\n\nModel:\nHolt\nSSE\n677.629\n\n\nOptimized:\nFalse\nAIC\n65.158\n\n\nTrend:\nAdditive\nBIC\n67.990\n\n\nSeasonal:\nNone\nAICC\n75.658\n\n\nSeasonal Periods:\nNone\nDate:\nMon, 28 Apr 2025\n\n\nBox-Cox:\nFalse\nTime:\n12:36:23\n\n\nBox-Cox Coeff.:\nNone\n\n\n\n\n\n\n\n\n\n\n\ncoeff\ncode\noptimized\n\n\nsmoothing_level\n0.7000000\nalpha\nFalse\n\n\nsmoothing_trend\n0.3000000\nbeta\nFalse\n\n\ninitial_level\n0.1300000\nl.0\nFalse\n\n\ninitial_trend\n-0.7000000\nb.0\nFalse\n\n\n\n\n\nGenerating a model with optimized values selected by the model\n\nNHLC_estimated_model = Holt(NHLC_eps, initialization_method = 'estimated', damped = True)\nNHLC_estimated_model_result = NHLC_estimated_model.fit()\nNHLC_estimated_model_result.summary()\n\nFutureWarning: the 'damped' keyword is deprecated, use 'damped_trend' instead.\n  NHLC_estimated_model = Holt(NHLC_eps, initialization_method = 'estimated', damped = True)\n/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-DEC will be used.\n  self._init_dates(dates, freq)\n\n\n\nHolt Model Results\n\n\nDep. Variable:\nEPS\nNo. Observations:\n15\n\n\nModel:\nHolt\nSSE\n503.166\n\n\nOptimized:\nTrue\nAIC\n62.693\n\n\nTrend:\nAdditive\nBIC\n66.233\n\n\nSeasonal:\nNone\nAICC\n78.693\n\n\nSeasonal Periods:\nNone\nDate:\nMon, 28 Apr 2025\n\n\nBox-Cox:\nFalse\nTime:\n12:36:28\n\n\nBox-Cox Coeff.:\nNone\n\n\n\n\n\n\n\n\n\n\n\ncoeff\ncode\noptimized\n\n\nsmoothing_level\n1.0000000\nalpha\nTrue\n\n\nsmoothing_trend\n0.000000\nbeta\nTrue\n\n\ninitial_level\n-0.1283881\nl.0\nTrue\n\n\ninitial_trend\n0.2582996\nb.0\nTrue\n\n\ndamping_trend\n0.8000000\nphi\nTrue\n\n\n\n\n\nVisualizing the best fit of the two models\n\nplt.figure(figsize=(10, 6))\nplt.plot(NHLC_model_known_result.fittedvalues, color = 'green', alpha = 0.7, linestyle = 'dotted', label = 'Make up parameters')\nplt.plot(NHLC_estimated_model_result.fittedvalues, color = 'red', alpha = 0.7, linestyle = 'dashed', label = 'Optimized parameters')\nplt.plot(NHLC_eps, color = 'black', alpha = 0.9, linestyle = 'dashdot', label = 'Actual Data')\nplt.title('NHLC EPS Forecast model fit')\nplt.xlabel('Year')\nplt.ylabel('EPS')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n*By visualizing both the known model (manually set parameters) and optimized model against the actual EPS data (black line), it is evident that neither of the models do a good job of fitting with actual values. This is primarily because of the stuctural break that is introduced in the year 2020 where the company experiences a big break in the trend because of Covid shutdown and the two models are not able to capture this. Even when we see the initial years there is a slight lag in both the models compared to actual values and this lag gets inflated for the negative slope and is delayed for the optimized model to 2022 and for know model to 2023. Holt‚Äôs linear method generally assumes a continuous, somewhat smooth trend (either rising or falling) but with the exponential downfall in 2020, this assumption gets violated. Another indicators is that the smoothing_level is very aggressive alpha is 1 which indicates that the optimized model places entire weight on the recent observations and is highly influenced by the 2020 value and hence overestimates the downfall and misses on the correct in 2021. Even the dampening factor does not work here and now there are only two options: 1. Modeling using ARIMA - However, 2020 is a shock trend which even ARIMA cannot smooth out and it shouldn‚Äôt be because it is a natural phenomenon that was drastic in its magnitude and hence the entire series cannot be used because ARIMA requires stationarity in time-series and this shock violates that which means we would have to use post 2020 data and with that 2nd option becomes faster and easier to interpret. 2. Holt‚Äôs Linear model with data post 2020 only.\nHolt‚Äôs model for NHLC with post 2020 data\n\nNHLC_eps_reduced = NHLC_eps.loc['2021-12-31':]\nNHLC_eps_reduced\n\n\n\n\n\n\n\n\nEPS\n\n\nYear\n\n\n\n\n\n2021-12-31\n-12.33\n\n\n2022-12-31\n-5.41\n\n\n2023-12-31\n0.39\n\n\n2024-12-31\n2.09\n\n\n\n\ndtype: float64\n\n\n\nNHLC_model2 = Holt(NHLC_eps_reduced, initialization_method = 'estimated', damped_trend = True)\nNHLC_model2_result = NHLC_model2.fit()\nNHLC_model2_result.summary()\n\n/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-DEC will be used.\n  self._init_dates(dates, freq)\n\n\n\nHolt Model Results\n\n\nDep. Variable:\nEPS\nNo. Observations:\n4\n\n\nModel:\nHolt\nSSE\n2.815\n\n\nOptimized:\nTrue\nAIC\n8.595\n\n\nTrend:\nAdditive\nBIC\n5.527\n\n\nSeasonal:\nNone\nAICC\ninf\n\n\nSeasonal Periods:\nNone\nDate:\nMon, 28 Apr 2025\n\n\nBox-Cox:\nFalse\nTime:\n12:36:45\n\n\nBox-Cox Coeff.:\nNone\n\n\n\n\n\n\n\n\n\n\n\ncoeff\ncode\noptimized\n\n\nsmoothing_level\n1.4901e-08\nalpha\nTrue\n\n\nsmoothing_trend\n3.7902e-09\nbeta\nTrue\n\n\ninitial_level\n-19.487964\nl.0\nTrue\n\n\ninitial_trend\n7.6528145\nb.0\nTrue\n\n\ndamping_trend\n0.8000000\nphi\nTrue\n\n\n\n\n\n\nplt.figure(figsize=(10, 6))\nplt.plot(NHLC_model2_result.fittedvalues, color = 'green', alpha = 0.7, linestyle = 'dotted', label = 'Optimized parameters')\nplt.plot(NHLC_eps, color = 'black', alpha = 0.9, linestyle = 'dashdot', label = 'Actual Data')\nplt.title('NHLC EPS Forecast model2 fit')\nplt.xlabel('Year')\nplt.ylabel('EPS')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nThe fit is immediately visible when we use the data post 2020 shock, even with AIC comparison with previous optimized model on entire data series (8.595 v/s 62.963) and this confirms that we can go ahead with predicting the EPS for 2025.\n\nNHLC_model2_result.forecast(steps = 1)\n\n\n\n\n\n\n\n\n0\n\n\n\n\n2025-12-31\n6.237737\n\n\n\n\ndtype: float64\n\n\nThe forecast for EPS is 6.25 which does look a high jump from 2024, however there are several qualitative factors that justify this forecast for Norwegian Cruise Lines, in May 2024 NCLH launched the ‚ÄúCharting the Course‚Äù strategy focusing on 4 pillars: people, product, growth platform and performance. They had set the ambition of adjusted EPS of (2.45) in this strategic plan but there are chances they may well exceed this benchmark because they were are $2.09 by end of 2024 itself and this is the goal for year 2026. Another major postive and transformative step they have taken is adding eight state-of-the-art vessels, adding approximately 25000 berths across its three brands, there are several brand initiatives and enhanced guest experiences which can contribute to repeat business for them and will ultimately lead them to their Balance sheet strengthening.(Carnival Corporation & plc, 2024)\nCCL Forecast\n\nCCL_df['Year'] = pd.to_datetime(CCL_df['Year'], format='%Y') + pd.offsets.YearEnd(0)\nCCL_df.set_index('Year', inplace=True)\n\n\nCCL_eps = CCL_df['EPS']\nCCL_eps.sort_index(inplace=True)\nCCL_eps = CCL_eps.loc['2021-12-31':]\nCCL_eps\n\n\n\n\n\n\n\n\nEPS\n\n\nYear\n\n\n\n\n\n2021-12-31\n-8.46\n\n\n2022-12-31\n-5.16\n\n\n2023-12-31\n-0.06\n\n\n2024-12-31\n1.44\n\n\n\n\ndtype: float64\n\n\n\nfrom typing import Any\nfrom statsmodels.tsa.api import Holt\n\nCCL_model = Holt(CCL_eps, initialization_method = 'known', initial_level = -8.46,\n                  initial_trend = 2.30, exponential = False)\nCCL_model_result = CCL_model.fit(smoothing_level = 0.90, smoothing_trend = 0.10,\n                                  optimized = False, damping_trend = 0.70)\nCCL_model_result.summary()\n\n/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-DEC will be used.\n  self._init_dates(dates, freq)\n\n\n\nHolt Model Results\n\n\nDep. Variable:\nEPS\nNo. Observations:\n4\n\n\nModel:\nHolt\nSSE\n15.769\n\n\nOptimized:\nFalse\nAIC\n13.487\n\n\nTrend:\nAdditive\nBIC\n11.032\n\n\nSeasonal:\nNone\nAICC\ninf\n\n\nSeasonal Periods:\nNone\nDate:\nMon, 28 Apr 2025\n\n\nBox-Cox:\nFalse\nTime:\n03:09:47\n\n\nBox-Cox Coeff.:\nNone\n\n\n\n\n\n\n\n\n\n\n\ncoeff\ncode\noptimized\n\n\nsmoothing_level\n0.9000000\nalpha\nFalse\n\n\nsmoothing_trend\n0.1000000\nbeta\nFalse\n\n\ninitial_level\n-8.4600000\nl.0\nFalse\n\n\ninitial_trend\n2.3000000\nb.0\nFalse\n\n\n\n\n\n\nCCL_model2 = Holt(CCL_eps, initialization_method = 'estimated', damped_trend = True)\nCCL_model2_result = CCL_model2.fit()\nCCL_model2_result.summary()\n\n/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-DEC will be used.\n  self._init_dates(dates, freq)\n\n\n\nHolt Model Results\n\n\nDep. Variable:\nEPS\nNo. Observations:\n4\n\n\nModel:\nHolt\nSSE\n1.569\n\n\nOptimized:\nTrue\nAIC\n6.255\n\n\nTrend:\nAdditive\nBIC\n3.187\n\n\nSeasonal:\nNone\nAICC\ninf\n\n\nSeasonal Periods:\nNone\nDate:\nMon, 28 Apr 2025\n\n\nBox-Cox:\nFalse\nTime:\n03:09:47\n\n\nBox-Cox Coeff.:\nNone\n\n\n\n\n\n\n\n\n\n\n\ncoeff\ncode\noptimized\n\n\nsmoothing_level\n1.4901e-08\nalpha\nTrue\n\n\nsmoothing_trend\n9.4321e-09\nbeta\nTrue\n\n\ninitial_level\n-14.040933\nl.0\nTrue\n\n\ninitial_trend\n5.3617653\nb.0\nTrue\n\n\ndamping_trend\n0.8000000\nphi\nTrue\n\n\n\n\n\n\nplt.figure(figsize=(10, 6))\nplt.plot(CCL_model_result.fittedvalues, color = 'green', alpha = 0.7, linestyle = 'dotted', label = 'Known parameters')\nplt.plot(CCL_model2_result.fittedvalues, color = 'red', alpha = 0.7, linestyle = 'dashed', label = 'Optimized parameters')\nplt.plot(NHLC_eps, color = 'black', alpha = 0.9, linestyle = 'dashdot', label = 'Actual Data')\nplt.title('CCL EPS Forecast model fit comparison')\nplt.xlabel('Year')\nplt.ylabel('EPS')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nCCL_model2_result.forecast(steps = 1)\n\n\n\n\n\n\n\n\n0\n\n\n\n\n2025-12-31\n3.983178\n\n\n\n\ndtype: float64\n\n\nSame as NHLC, even with Carnival Corporation we considered the data post 2020 exponential drop, and we tested the data with two models and similar to NHLC the optimized parameter model had a better fit to actual values. Hence that model was used for the forecast. The resulting EPS forecast for Carnival in 2025 is 3.98 which seems realistic and achievable for the company. It is also justifiable qualitatively as post pandemic Carnival introduced new ships, including the Carnival Jubilee, and ordered additional excel-class vessels to enhance guest experience and modernize its fleet and increase capacity. The company has reduced its overall debt by $8 billion in 2024 and also implemented a premium pricing strategy, leading to a record revenue of 25 billion dollars. Based on this it can be concluded that this forecast seems apparent for the company based on their last year performance.(Norwegian Cruise Line Holdings, 2024)\nReferences:  1. Carnival Corporation & plc. (2024). 2024 annual report. https://www.carnivalcorp.com/wp-content/uploads/2024/08/Carnival-Corporation-plc-2024-Annual-Report.pdf 2. Norwegian Cruise Line Holdings. (2024, February 27). Norwegian Cruise Line Holdings reports strong fourth quarter and record full year 2023 results. https://www.nclhltd.com/investors/news-events/press-releases/detail/677/norwegian-cruise-line-holdings-reports-strong-fourth\nConjoint Analysis and Recommendations\nLoading the voyage_options guest ratings dataset and the vendor cost dataset for analyzing price tradeoffs between amenities. \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nvoyage_options = pd.read_csv('voyage_options.csv')\nvendor_cost = pd.read_csv('vendor_costs_654.csv')\n\n\nvoyage_options.head()\n\n\n    \n\n\n\n\n\n\nentertainment\ndining\ncabin\namenities\ncocktail_credits\navg_rating\n\n\n\n\n0\nEast Coast Folk\nMaine Lobster Nova Scotia Seafood Buffet\nCozy with Fireplace\nTop Deck Hot Tubs\n1\n8.313079\n\n\n1\nEast Coast Folk\nMaine Lobster Nova Scotia Seafood Buffet\nCozy with Fireplace\nTop Deck Hot Tubs\n2\n9.435885\n\n\n2\nEast Coast Folk\nMaine Lobster Nova Scotia Seafood Buffet\nCozy with Fireplace\nTop Deck Hot Tubs\n3\n8.540985\n\n\n3\nEast Coast Folk\nMaine Lobster Nova Scotia Seafood Buffet\nCozy with Fireplace\nWinter Wellness Spa\n1\n8.415454\n\n\n4\nEast Coast Folk\nMaine Lobster Nova Scotia Seafood Buffet\nCozy with Fireplace\nWinter Wellness Spa\n2\n9.241294\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\nvendor_cost.head()\n\n\n    \n\n\n\n\n\n\nItem\nItem Category\nCost Per Passenger (Dollars)\n\n\n\n\n0\nEast Coast Folk\nentertainment\n25.0\n\n\n1\nJazz Blues\nentertainment\n19.0\n\n\n2\nAcoustic Showcase\nentertainment\n12.0\n\n\n3\nDJ Dance\nentertainment\n9.0\n\n\n4\nMaine Lobster Nova Scotia Seafood Buffet\ndining\n24.0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\nCleaning the DJ dance value in the entertainment variable under voyage_options data frame to match it with vendor_cost data frame for easier mapping later on.\n\nvoyage_options['entertainment'] = voyage_options['entertainment'].replace('DJ_Dance', 'DJ Dance')\n\n\nvoyage_options['cocktail_credits'] = voyage_options['cocktail_credits'].replace(1, '1 cocktail tickets per passenger')\nvoyage_options['cocktail_credits'] = voyage_options['cocktail_credits'].replace(2, '2 cocktail tickets per passenger')\nvoyage_options['cocktail_credits'] = voyage_options['cocktail_credits'].replace(3, '3 cocktail tickets per passenger')\n\n\nvendor_cost['Item Category'] = vendor_cost['Item Category'].replace('cocktail', 'cocktail_credits')\n\nConverting categorical variables into dummy variables for conjoint modeling\n\nvoyage_options2 = pd.get_dummies(voyage_options, drop_first = True, columns = ['entertainment',\n                                 'dining', 'cabin', 'amenities', 'cocktail_credits'])\nvoyage_options2\n\n\n    \n\n\n\n\n\n\navg_rating\nentertainment_DJ Dance\nentertainment_East Coast Folk\nentertainment_Jazz Blues\ndining_Coastal Tapas & Tasting Stations\ndining_Formal Multi-Course Plated\ndining_Maine Lobster Nova Scotia Seafood Buffet\ncabin_Modern Minimalist\ncabin_Nautical Chic\ncabin_Romantic Escape\namenities_Top Deck Hot Tubs\namenities_Winter Wellness Spa\ncocktail_credits_2 cocktail tickets per passenger\ncocktail_credits_3 cocktail tickets per passenger\n\n\n\n\n0\n8.313079\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\n\n\n1\n9.435885\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\n\n\n2\n8.540985\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nTrue\n\n\n3\n8.415454\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\n\n\n4\n9.241294\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n571\n3.275835\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nTrue\nFalse\n\n\n572\n5.478078\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nTrue\nFalse\nTrue\n\n\n573\n6.439684\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n\n\n574\n3.069132\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\n\n\n575\n6.196628\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nTrue\n\n\n\n\n576 rows √ó 14 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nSeparating the independent and dependent variables, and using them to fit in the regression model to generate coefficients for analysis\n\nX = voyage_options2.drop(columns = ['avg_rating'])\ny = voyage_options2['avg_rating']\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nregressor = LinearRegression()\nregressor.fit(X, y)\nLinearRegression()\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniNot fittedLinearRegression() \n\n\n\ncoef_df = pd.DataFrame(regressor.coef_, X.columns, columns = ['Coefficient'])\ncoef_df\n\n\n    \n\n\n\n\n\n\nCoefficient\n\n\n\n\nentertainment_DJ Dance\n-0.697778\n\n\nentertainment_East Coast Folk\n0.444300\n\n\nentertainment_Jazz Blues\n0.355375\n\n\ndining_Coastal Tapas & Tasting Stations\n0.292936\n\n\ndining_Formal Multi-Course Plated\n-0.768749\n\n\ndining_Maine Lobster Nova Scotia Seafood Buffet\n1.497222\n\n\ncabin_Modern Minimalist\n-0.449679\n\n\ncabin_Nautical Chic\n0.312436\n\n\ncabin_Romantic Escape\n0.032533\n\n\namenities_Top Deck Hot Tubs\n0.902993\n\n\namenities_Winter Wellness Spa\n0.077683\n\n\ncocktail_credits_2 cocktail tickets per passenger\n0.425807\n\n\ncocktail_credits_3 cocktail tickets per passenger\n-0.533080\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\ncoef_df = coef_df.reset_index()\ncoef_df.columns = ['Variable', 'Coefficient']\ncoef_df\n\n\n    \n\n\n\n\n\n\nVariable\nCoefficient\n\n\n\n\n0\nentertainment_DJ Dance\n-0.697778\n\n\n1\nentertainment_East Coast Folk\n0.444300\n\n\n2\nentertainment_Jazz Blues\n0.355375\n\n\n3\ndining_Coastal Tapas & Tasting Stations\n0.292936\n\n\n4\ndining_Formal Multi-Course Plated\n-0.768749\n\n\n5\ndining_Maine Lobster Nova Scotia Seafood Buffet\n1.497222\n\n\n6\ncabin_Modern Minimalist\n-0.449679\n\n\n7\ncabin_Nautical Chic\n0.312436\n\n\n8\ncabin_Romantic Escape\n0.032533\n\n\n9\namenities_Top Deck Hot Tubs\n0.902993\n\n\n10\namenities_Winter Wellness Spa\n0.077683\n\n\n11\ncocktail_credits_2 cocktail tickets per passenger\n0.425807\n\n\n12\ncocktail_credits_3 cocktail tickets per passenger\n-0.533080\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\ncoef_df['Variable'] = coef_df['Variable'].str.replace('_', ' ', n = 1)\ncoef_df\n\n\n    \n\n\n\n\n\n\nVariable\nCoefficient\n\n\n\n\n0\nentertainment DJ Dance\n-0.697778\n\n\n1\nentertainment East Coast Folk\n0.444300\n\n\n2\nentertainment Jazz Blues\n0.355375\n\n\n3\ndining Coastal Tapas & Tasting Stations\n0.292936\n\n\n4\ndining Formal Multi-Course Plated\n-0.768749\n\n\n5\ndining Maine Lobster Nova Scotia Seafood Buffet\n1.497222\n\n\n6\ncabin Modern Minimalist\n-0.449679\n\n\n7\ncabin Nautical Chic\n0.312436\n\n\n8\ncabin Romantic Escape\n0.032533\n\n\n9\namenities Top Deck Hot Tubs\n0.902993\n\n\n10\namenities Winter Wellness Spa\n0.077683\n\n\n11\ncocktail credits_2 cocktail tickets per passenger\n0.425807\n\n\n12\ncocktail credits_3 cocktail tickets per passenger\n-0.533080\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\ncoef_df['Variable'] = coef_df['Variable'].str.lower().str.replace('_', ' ').str.strip()\nvendor_cost['Item'] = vendor_cost['Item'].str.lower().str.replace('_', ' ').str.strip()\n\n\nvendor_cost['Variable'] =  vendor_cost['Item Category'] + ' ' + vendor_cost['Item']\n\n\nvendor_cost\n\n\n    \n\n\n\n\n\n\nItem\nItem Category\nCost Per Passenger (Dollars)\nVariable\n\n\n\n\n0\neast coast folk\nentertainment\n25.00\nentertainment east coast folk\n\n\n1\njazz blues\nentertainment\n19.00\nentertainment jazz blues\n\n\n2\nacoustic showcase\nentertainment\n12.00\nentertainment acoustic showcase\n\n\n3\ndj dance\nentertainment\n9.00\nentertainment dj dance\n\n\n4\nmaine lobster nova scotia seafood buffet\ndining\n24.00\ndining maine lobster nova scotia seafood buffet\n\n\n5\nformal multi-course plated\ndining\n31.00\ndining formal multi-course plated\n\n\n6\ncoastal tapas & tasting stations\ndining\n16.50\ndining coastal tapas & tasting stations\n\n\n7\ncasual fireside grill with hot cider\ndining\n17.25\ndining casual fireside grill with hot cider\n\n\n8\ncozy with fireplace\ncabin\n9.00\ncabin cozy with fireplace\n\n\n9\nnautical chic\ncabin\n15.00\ncabin nautical chic\n\n\n10\nromantic escape\ncabin\n12.00\ncabin romantic escape\n\n\n11\nmodern minimalist\ncabin\n8.00\ncabin modern minimalist\n\n\n12\ntop deck hot tubs\namenities\n13.50\namenities top deck hot tubs\n\n\n13\nwinter wellness spa\namenities\n7.50\namenities winter wellness spa\n\n\n14\nfireside live music\namenities\n9.00\namenities fireside live music\n\n\n15\n1 cocktail ticket per passenger\ncocktail_credits\n4.00\ncocktail_credits 1 cocktail ticket per passenger\n\n\n16\n2 cocktail tickets per passenger\ncocktail_credits\n8.00\ncocktail_credits 2 cocktail tickets per passenger\n\n\n17\n3 cocktail tickets per passenger\ncocktail_credits\n12.00\ncocktail_credits 3 cocktail tickets per passenger\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\n\ncoef_df_cost = pd.merge(coef_df, vendor_cost[['Cost Per Passenger (Dollars)', 'Variable']], on = 'Variable', how = 'left')\ncoef_df_cost\n\n\n    \n\n\n\n\n\n\nVariable\nCoefficient\nCost Per Passenger (Dollars)\n\n\n\n\n0\nentertainment dj dance\n-0.697778\n9.0\n\n\n1\nentertainment east coast folk\n0.444300\n25.0\n\n\n2\nentertainment jazz blues\n0.355375\n19.0\n\n\n3\ndining coastal tapas & tasting stations\n0.292936\n16.5\n\n\n4\ndining formal multi-course plated\n-0.768749\n31.0\n\n\n5\ndining maine lobster nova scotia seafood buffet\n1.497222\n24.0\n\n\n6\ncabin modern minimalist\n-0.449679\n8.0\n\n\n7\ncabin nautical chic\n0.312436\n15.0\n\n\n8\ncabin romantic escape\n0.032533\n12.0\n\n\n9\namenities top deck hot tubs\n0.902993\n13.5\n\n\n10\namenities winter wellness spa\n0.077683\n7.5\n\n\n11\ncocktail credits 2 cocktail tickets per passenger\n0.425807\nNaN\n\n\n12\ncocktail credits 3 cocktail tickets per passenger\n-0.533080\nNaN\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nAnalysis of the coefficients generated for each iten category: The benchmark for selection of experiences provided by the Lobster Land management is 75 dollars per guest. In that case there have to be tradeoffs between the most preferred option by the guests and the costs associated with it. From an analysis perspective, it is essential to highlight the combination that is most preferred by the guest and then narrow the recommendation with a top-down approach. From comparison across categories, it is noticeable that guests have strong positive opinions about ‚Äúmaine lobster Nova Scotia Buffet‚Äù in comparison to other amenities provided so there should be a strong case to leave this out. If entertainment category in itself is analyzed, ‚ÄôDJ dance is the least preferred option by the guests, while the most preferred is east coast folk and if we calculate the incremental benefit from DJ dance to East folk it is 0.253 however when we move further down to Jazz Blues the difference is only 0.01 in preference so either of the options work well considering cost trade-offs. We would still prefer analyzing other dining options and apart from the Buffet being the most preferred, the formal mult-course plated is less preferred than the Casual Fireside Grill so that can be completely ignored, and the second preferred option is coastal tapas and tasting stations however the drop in preference is 1.2 which is significant, the reason could be tasting stations while offer variety but is limited in quantity and we can speculate that guests are fans of seafood and would not want to miss a chance of enjoying the famous Lobster of Maine and the exclusive seafood from Nova Scotia, Canada. Even with the entertainment options, we can speculate that most of the guests are in their middle age and have opted for a cruise experience to have a laid back and relaxed experience and the vibe of East folk maritime music and Jazz aligns well with the sea and the open sky. Another important component of this experience is the cabin for the guests which is basically their home for the night, the most preferred option is the Nautical chic which resonates with their choice of music of maritimes and has upscale comfort, if we drop to the 2nd option the difference in preference is approximately 0.28 with Romantic Escape. However, the offer under Romantic escape is luxurious with a balcony view which is perfect for couples and so this tradeoff for the cost and the offering seems to align with the audience and is reasonable. Coming down to amenities - there is a strong preference for top deck hot tubs which we have seen have been a recquisite in many cruise lines and in this it seems to be a non-negotiator for Lobster land guests as well. Although the cost savings in alternative are healthy but the difference in ratings by guests seem to be considerable to make a trade off. Finally moving to the cocktail credits which let the guests enjoy free coctails that can be availed at any bar onboard, there is a strong preference for 2 free cocktails and interestingly guests don‚Äôt feel positively about 3 free drinks and that can be attributed to most people choosing middleground option or since majority are couple guests, the preference here would be 2 free drinks per individual. The most important tradeoff here is between free cocktails and entertainment, while both the categories preferred options seem to have approximately same coefficients, it is important to note that this an optional incentive and entertainment is more seeked on a voyage than free drinks, so even with 1 free drink per passenger the guests would be okay but a compromise on entertainment category from Jazz Blues to Acoustic which is the reference can influence the guests to choose other cruise lines.\n*Final Recommendation for the Lobster Land Management: The major components that are critical for an enhanced voyage experience based on the guests ratings are: Dining, amenities, entertainment and cabin in this mentioned hierarchy. For Dining - Maine Lobster and Nova Scotia seafood Buffet which consists of a premium buffet will be included in the experience at the cost of 24 dollars per passenger. Amenities - Top deck hot tubs with panoramic ocean views, open day and night is strongly preferred and should be part of the esxperience at the cost of 13.5 dollars per passenger. Entertainment - Although East Coast folk live music performance is the most preferred as per the guest ratings but the second preferred option Jazz Blues helps manage the cost trade offs better and hence that will part of the offering at 19 dollars per passenger. Cabin - Although Nautical chic cabins are most preferred by the guests, even romantic escape themed cabins better suit the overall experience and help manage the cost tradeoffs better. These will be offered at 12 dollars per passenger. Cocktail_credits - Finally, the optional incentive of free cocktails per passenger is considered, the preference from the guests is to have 2 free coctails per passenger, however to better consider the entertainment choices for the guest, the baseline option of 1 free drink per passenger is chosen to accomodate the 2nd best entertainment choice.\nFinal combination - Maine Lobster Nova Scotia Seafood Buffet + Jazz Blues + Romantic Escape + Top Deck Hot Tubs + 1 free cocktail_credit per passenger\nFinal cost - 24 + 19 + 12 + 13.5 + 4 = $72.5 So the recommendation is within the allocated budget and considers the guest preferences in the best possible way.*\n\n\nClassification\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nnp.random.seed(654)\n\nLoad & Clean the Dataset\n\ncancellations = pd.read_csv('cruise_cancellations.csv')\ncancellations.head()\n\n\n    \n\n\n\n\n\n\nage\nbooking_lead_time\ntrip_length\ncabin_type\ngroup_size\nloyalty_status\npaid_in_full\nprior_cruises\ncustomer_income\nemail_engagement_score\nphone_verified\nhas_insurance\non_mailing_list\nwebsite_visits_last_month\nsurvey_participation\npreferred_contact_method\ntravel_history_score\nreferral_source\ngift_certificate_used\ncanceled\n\n\n\n\n0\n56\n131\n7\nOceanview\n5\nNaN\n1\n1\n134181.36\n0.41\n1\n0\n1\n4\nNo\nPhone\n62.70\nFriend\n0\n0\n\n\n1\n69\n293\n5\nOceanview\n5\nNaN\n1\n2\n104770.24\n0.34\n1\n0\n1\n1\nNo\nEmail\n56.59\nFriend\n0\n0\n\n\n2\n46\n171\n7\nBalcony\n3\nNaN\n0\n1\n109135.01\n0.38\n1\n0\n0\n3\nYes\nPhone\n57.58\nAd\n0\n1\n\n\n3\n32\n183\n3\nBalcony\n2\nSilver\n0\n0\n80108.53\n0.58\n0\n0\n0\n2\nNo\nEmail\n14.75\nSearch Engine\n0\n1\n\n\n4\n60\n364\n10\nOceanview\n3\nSilver\n0\n2\n73401.55\n0.50\n1\n0\n1\n3\nPartial\nPhone\n47.49\nAd\n0\n0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\ncancellations.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2000 entries, 0 to 1999\nData columns (total 20 columns):\n #   Column                     Non-Null Count  Dtype  \n---  ------                     --------------  -----  \n 0   age                        2000 non-null   int64  \n 1   booking_lead_time          2000 non-null   int64  \n 2   trip_length                2000 non-null   int64  \n 3   cabin_type                 2000 non-null   object \n 4   group_size                 2000 non-null   int64  \n 5   loyalty_status             1016 non-null   object \n 6   paid_in_full               2000 non-null   int64  \n 7   prior_cruises              2000 non-null   int64  \n 8   customer_income            2000 non-null   float64\n 9   email_engagement_score     2000 non-null   float64\n 10  phone_verified             2000 non-null   int64  \n 11  has_insurance              2000 non-null   int64  \n 12  on_mailing_list            2000 non-null   int64  \n 13  website_visits_last_month  2000 non-null   int64  \n 14  survey_participation       2000 non-null   object \n 15  preferred_contact_method   2000 non-null   object \n 16  travel_history_score       2000 non-null   float64\n 17  referral_source            2000 non-null   object \n 18  gift_certificate_used      2000 non-null   int64  \n 19  canceled                   2000 non-null   int64  \ndtypes: float64(3), int64(12), object(5)\nmemory usage: 312.6+ KB\n\n\n\ncancellations['loyalty_status'] = cancellations['loyalty_status'].fillna('None')\n\n\ncancellations['canceled'].value_counts()\n\n\n\n\n\n\n\n\ncount\n\n\ncanceled\n\n\n\n\n\n0\n1447\n\n\n1\n553\n\n\n\n\ndtype: int64\n\n\n1447 NOT cancelled & 553 cancelled\n\ncancellations.describe()\n\n\n    \n\n\n\n\n\n\nage\nbooking_lead_time\ntrip_length\ngroup_size\npaid_in_full\nprior_cruises\ncustomer_income\nemail_engagement_score\nphone_verified\nhas_insurance\non_mailing_list\nwebsite_visits_last_month\ntravel_history_score\ngift_certificate_used\ncanceled\n\n\n\n\ncount\n2000.000000\n2000.000000\n2000.000000\n2000.00000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n2000.000000\n\n\nmean\n49.114000\n182.184000\n7.237000\n3.00500\n0.714500\n1.476500\n84527.364645\n0.503105\n0.845500\n0.398500\n0.644500\n2.989500\n50.376555\n0.092000\n0.276500\n\n\nstd\n17.926564\n105.209014\n3.151793\n1.46835\n0.451765\n1.204647\n29639.635285\n0.144368\n0.361518\n0.489712\n0.478784\n1.700834\n14.904381\n0.289098\n0.447379\n\n\nmin\n18.000000\n1.000000\n3.000000\n1.00000\n0.000000\n0.000000\n-7095.200000\n0.010000\n0.000000\n0.000000\n0.000000\n0.000000\n0.370000\n0.000000\n0.000000\n\n\n25%\n34.000000\n92.000000\n5.000000\n2.00000\n0.000000\n1.000000\n64681.840000\n0.400000\n1.000000\n0.000000\n0.000000\n2.000000\n40.795000\n0.000000\n0.000000\n\n\n50%\n49.000000\n177.000000\n7.000000\n3.00000\n1.000000\n1.000000\n84033.095000\n0.500000\n1.000000\n0.000000\n1.000000\n3.000000\n50.535000\n0.000000\n0.000000\n\n\n75%\n65.000000\n273.250000\n10.000000\n4.00000\n1.000000\n2.000000\n104225.347500\n0.600000\n1.000000\n1.000000\n1.000000\n4.000000\n60.265000\n0.000000\n1.000000\n\n\nmax\n79.000000\n364.000000\n14.000000\n9.00000\n1.000000\n7.000000\n184530.610000\n0.930000\n1.000000\n1.000000\n1.000000\n10.000000\n100.000000\n1.000000\n1.000000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\ncancellations.loc[cancellations['customer_income'] &lt; 0, 'customer_income'] = cancellations['customer_income'].median()\n\n\ncancellations_dummified = pd.get_dummies(cancellations, drop_first=True)\n\n\nX = cancellations_dummified.drop(columns=['canceled'])\ny = cancellations_dummified['canceled']\n\nprint(X.shape)\nprint(y.shape)\n\n(2000, 27)\n(2000,)\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.25, random_state=654, stratify=y\n)\n\nprint(X_train.shape)\nprint(X_test.shape)\n\n(1500, 27)\n(500, 27)\n\n\n\nclf = RandomForestClassifier(random_state=654)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.75      0.92      0.83       362\n           1       0.50      0.21      0.30       138\n\n    accuracy                           0.72       500\n   macro avg       0.63      0.57      0.56       500\nweighted avg       0.68      0.72      0.68       500\n\n\n\n\ncompare_means = cancellations_dummified.groupby('canceled').mean(numeric_only=True)\ncompare_means.T\n\n\n    \n\n\n\n\n\ncanceled\n0\n1\n\n\n\n\nage\n49.087768\n49.182640\n\n\nbooking_lead_time\n188.024188\n166.902351\n\n\ntrip_length\n7.299240\n7.074141\n\n\ngroup_size\n3.000691\n3.016275\n\n\npaid_in_full\n0.774015\n0.558770\n\n\nprior_cruises\n1.487906\n1.446655\n\n\ncustomer_income\n86407.919599\n80088.122251\n\n\nemail_engagement_score\n0.504692\n0.498951\n\n\nphone_verified\n0.838286\n0.864376\n\n\nhas_insurance\n0.395301\n0.406872\n\n\non_mailing_list\n0.653766\n0.620253\n\n\nwebsite_visits_last_month\n2.988252\n2.992767\n\n\ntravel_history_score\n50.325045\n50.511338\n\n\ngift_certificate_used\n0.082930\n0.115732\n\n\ncabin_type_Interior\n0.300622\n0.358047\n\n\ncabin_type_Oceanview\n0.295093\n0.269439\n\n\ncabin_type_Suite\n0.096752\n0.077758\n\n\nloyalty_status_None\n0.403594\n0.723327\n\n\nloyalty_status_Platinum\n0.114029\n0.041591\n\n\nloyalty_status_Silver\n0.305460\n0.159132\n\n\nsurvey_participation_Partial\n0.214927\n0.197107\n\n\nsurvey_participation_Yes\n0.292329\n0.309222\n\n\npreferred_contact_method_Phone\n0.340705\n0.341772\n\n\npreferred_contact_method_Text\n0.335867\n0.321881\n\n\nreferral_source_Friend\n0.231513\n0.269439\n\n\nreferral_source_Search Engine\n0.262612\n0.222423\n\n\nreferral_source_Social Media\n0.253628\n0.267631\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\nPassengers with no loyalty status, lower income, and unpaid bookings are much more likely to cancel, and they tend to book less premium cabins.\nIteration 1\n\nX_train = X_train.astype({col: 'int' for col in X_train.select_dtypes('bool').columns})\nX_train_sm = sm.add_constant(X_train)\nlog_model = sm.Logit(y_train, X_train_sm)\nlog_res = log_model.fit()\nprint(log_res.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.497151\n         Iterations 6\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:               canceled   No. Observations:                 1500\nModel:                          Logit   Df Residuals:                     1472\nMethod:                           MLE   Df Model:                           27\nDate:                Mon, 28 Apr 2025   Pseudo R-squ.:                  0.1571\nTime:                        03:09:52   Log-Likelihood:                -745.73\nconverged:                       True   LL-Null:                       -884.67\nCovariance Type:            nonrobust   LLR p-value:                 1.787e-43\n==================================================================================================\n                                     coef    std err          z      P&gt;|z|      [0.025      0.975]\n--------------------------------------------------------------------------------------------------\nconst                              0.0275      0.596      0.046      0.963      -1.142       1.197\nage                               -0.0005      0.004     -0.148      0.882      -0.008       0.007\nbooking_lead_time                 -0.0027      0.001     -4.321      0.000      -0.004      -0.001\ntrip_length                       -0.0338      0.021     -1.640      0.101      -0.074       0.007\ngroup_size                         0.0070      0.044      0.158      0.874      -0.080       0.094\npaid_in_full                      -1.2288      0.139     -8.863      0.000      -1.501      -0.957\nprior_cruises                     -0.0884      0.054     -1.627      0.104      -0.195       0.018\ncustomer_income                -6.481e-06   2.23e-06     -2.912      0.004   -1.08e-05   -2.12e-06\nemail_engagement_score            -0.3032      0.440     -0.689      0.491      -1.165       0.559\nphone_verified                     0.1442      0.182      0.791      0.429      -0.213       0.502\nhas_insurance                      0.0868      0.131      0.662      0.508      -0.170       0.344\non_mailing_list                   -0.1939      0.133     -1.452      0.146      -0.455       0.068\nwebsite_visits_last_month          0.0463      0.038      1.207      0.227      -0.029       0.121\ntravel_history_score               0.0032      0.004      0.746      0.456      -0.005       0.012\ngift_certificate_used              0.5509      0.210      2.622      0.009       0.139       0.963\ncabin_type_Interior                0.4347      0.162      2.677      0.007       0.116       0.753\ncabin_type_Oceanview              -0.1157      0.171     -0.678      0.498      -0.450       0.219\ncabin_type_Suite                   0.0034      0.241      0.014      0.989      -0.468       0.475\nloyalty_status_None                1.6945      0.219      7.750      0.000       1.266       2.123\nloyalty_status_Platinum           -0.2042      0.328     -0.623      0.533      -0.847       0.438\nloyalty_status_Silver              0.1812      0.246      0.738      0.461      -0.300       0.663\nsurvey_participation_Partial       0.1398      0.168      0.833      0.405      -0.189       0.469\nsurvey_participation_Yes           0.0262      0.150      0.175      0.861      -0.267       0.320\npreferred_contact_method_Phone     0.0364      0.155      0.234      0.815      -0.268       0.340\npreferred_contact_method_Text     -0.1715      0.160     -1.069      0.285      -0.486       0.143\nreferral_source_Friend            -0.0344      0.184     -0.187      0.852      -0.395       0.326\nreferral_source_Search Engine     -0.2873      0.187     -1.536      0.125      -0.654       0.079\nreferral_source_Social Media      -0.0669      0.180     -0.371      0.710      -0.420       0.286\n==================================================================================================\n\n\nIteration 2\n\nvars_drop = [\n        'age',\n        'trip_length',\n        'group_size',\n        'prior_cruises',\n        'email_engagement_score',\n        'phone_verified',\n        'has_insurance',\n        'on_mailing_list',\n        'website_visits_last_month',\n        'travel_history_score',\n        'cabin_type_Interior',\n        'cabin_type_Oceanview',\n        'cabin_type_Suite',\n        'loyalty_status_Platinum',\n        'loyalty_status_Silver',\n        'survey_participation_Partial',\n        'survey_participation_Yes',\n        'preferred_contact_method_Phone',\n        'preferred_contact_method_Text',\n        'referral_source_Friend',\n        'referral_source_Search Engine',\n        'referral_source_Social Media'\n    ]\n\nX_train_2 = X_train.drop(columns=vars_drop)\nX_train_2_sm = sm.add_constant(X_train_2)\nlog_model_2 = sm.Logit(y_train, X_train_2)\nlog_reg_2 = log_model_2.fit()\nprint(log_reg_2.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.507632\n         Iterations 6\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:               canceled   No. Observations:                 1500\nModel:                          Logit   Df Residuals:                     1495\nMethod:                           MLE   Df Model:                            4\nDate:                Mon, 28 Apr 2025   Pseudo R-squ.:                  0.1393\nTime:                        03:09:52   Log-Likelihood:                -761.45\nconverged:                       True   LL-Null:                       -884.67\nCovariance Type:            nonrobust   LLR p-value:                 3.813e-52\n=========================================================================================\n                            coef    std err          z      P&gt;|z|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nbooking_lead_time        -0.0028      0.001     -5.091      0.000      -0.004      -0.002\npaid_in_full             -1.1794      0.127     -9.276      0.000      -1.429      -0.930\ncustomer_income       -7.101e-06   1.45e-06     -4.884      0.000   -9.95e-06   -4.25e-06\ngift_certificate_used     0.5182      0.206      2.521      0.012       0.115       0.921\nloyalty_status_None       1.5447      0.131     11.749      0.000       1.287       1.802\n=========================================================================================\n\n\nPassengers who haven‚Äôt paid in full, used a gift certificate, or lack a loyalty tier are significantly more likely to cancel. Meanwhile, passengers who booked further in advance or have higher income are less likely to cancel.\n\nX_train_final = X_train.drop(columns=vars_drop)\nX_test_final = X_test.drop(columns=vars_drop)\nlog_reg_model = LogisticRegression(max_iter=1000)\nlog_reg_model.fit(X_train_final, y_train)\ny_pred = log_reg_model.predict(X_test_final)\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\n\n              precision    recall  f1-score   support\n\n           0       0.76      0.89      0.82       362\n           1       0.45      0.25      0.32       138\n\n    accuracy                           0.71       500\n   macro avg       0.60      0.57      0.57       500\nweighted avg       0.67      0.71      0.68       500\n\n[[321  41]\n [104  34]]\n\n\n\nfrom sklearn.metrics import accuracy_score\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\nAccuracy: 0.71\n\n\n\nX_train_final.columns.tolist()\n\n['booking_lead_time',\n 'paid_in_full',\n 'customer_income',\n 'gift_certificate_used',\n 'loyalty_status_None']\n\n\n\ntest_passenger = pd.DataFrame([{\n    'booking_lead_time': 120,\n    'paid_in_full': 1,\n    'customer_income': 85000,\n    'gift_certificate_used': 0,\n    'loyalty_status_None': 0\n}])\n\n\nprediction = log_reg_model.predict(test_passenger)\n\nprobability = log_reg_model.predict_proba(test_passenger)[0][1]\n\nprint(\"Predicted class (1 = Canceled):\", prediction[0])\nprint(\"Predicted probability of cancellation:\", round(probability, 4))\n\nPredicted class (1 = Canceled): 0\nPredicted probability of cancellation: 0.1087\n\n\n\ntest_passenger_2 = pd.DataFrame([{\n    'booking_lead_time': 30,\n    'paid_in_full': 0,\n    'customer_income': 35000,\n    'gift_certificate_used': 1,\n    'loyalty_status_None': 0\n}])\n\nprediction_2 = log_reg_model.predict(test_passenger_2)\n\nprobability_2 = log_reg_model.predict_proba(test_passenger_2)[0][1]\n\nprint(\"Predicted class (1 = Canceled):\", prediction_2[0])\nprint(\"Predicted probability of cancellation:\", round(probability_2, 4))\n\nPredicted class (1 = Canceled): 1\nPredicted probability of cancellation: 0.52\n\n\nThe test passenger, who booked 120 days in advance, paid in full, has a loyalty level, has not used a gift certificate, and has a decent income, has a low risk of not traveling. In contrast, the second test passenger with a short booking lead time of 30 days, unpaid balance, used gift certificate, and has lower salary of $35,000 had a predicted probability of cancellation of 51.8%. This is consistent with the result of our model: passenger has a low risk of cancellation with longer lead time between booking and start of the cruise, payment in full, availability of loyalty level, and lack of gift certificate.\nThe cancellation prediction model offers valuable insights for Lobster Land management by identifying certain customer behaviors that are associated with a higher probability of canceling a cruise booking. The model shows that passengers who: have not paid for their cruise in full, are not participating in a loyalty program, or have used a gift certificate; are significantly more likely to cancel their reservation. On the other hand, those who: book in advance, have a higher income level, and paying in full; are significantly less likely to cancel their reservation.\nFrom the results of the model, it is clear that the most at-risk passengers have several key characteristics. Lack of loyalty status was found to be an especially strong sign - revealing that passengers who booked for the first time or once may be less committed or more likely to cancel due to changes in plans or price sensitivity. The use of gift vouchers was also correlated with a higher risk of cancellation, possibly reflecting lower investment or ‚Äòvacation gift‚Äô bookings that may be more casual.\nThe results of this classification model can and should be transformed into actionable strategies for both customer retention and operational planning. Passengers identified as high-risk of cancelling (those with unpaid balances, no loyalty status, or gift certificate usage) can be identified early in the booking lifecycle and prioritized for targeted outreach. Marketing teams can prepare automated follow-up emails, personalized confirmations or time-sensitive incentives to encourage payment completion or strengthen commitment to the booking. From an operational standpoint, knowing which segments of passengers are most likely to cancel will allow Lobster Land to better forecast occupancy, manage overbooking, and adjust staffing and provisioning expectations for their cruises. This way the model serves not only as a forecasting tool but also as a decision support system, helping Lobster Land to prepare in advance to potential cancellations rather than reacting after they occur.\n\n\nStrategic Memo\nseparate document\nattached here\n\n\nAB testing for Cruise Pics\n\nLoading the cruise_pics dataset in the environment. Understanding the dataset structure, checking for missing values, impossible values and performing some EDA.\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ncruise_pics = pd.read_csv('cruise_pics.csv')\ncruise_pics.head()\n\n\n    \n\n\n\n\n\n\nphoto\nclicked\ntime_on_page\nnum_followup_clicks\nrating_of_photo\ninterest_score\ndevice_type\ntime_of_day\nbooked_info_session\nshared_email\nsaved_photo\n\n\n\n\n0\nNight Glow\n0\n13.8\n0\n8.1\n6.76\ndesktop\nafternoon\n0\n1\n0\n\n\n1\nNight Glow\n0\n18.8\n0\n7.3\n6.42\nmobile\nmorning\n0\n0\n0\n\n\n2\nNight Glow\n0\n9.9\n0\n7.8\n6.34\nmobile\nafternoon\n0\n0\n0\n\n\n3\nNight Glow\n0\n7.9\n0\n7.4\n5.95\ndesktop\nafternoon\n0\n0\n0\n\n\n4\nNight Glow\n1\n73.0\n2\n7.4\n16.70\nmobile\nafternoon\n0\n0\n0\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\ncruise_pics.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1007 entries, 0 to 1006\nData columns (total 11 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   photo                1007 non-null   object \n 1   clicked              1007 non-null   int64  \n 2   time_on_page         1007 non-null   float64\n 3   num_followup_clicks  1007 non-null   int64  \n 4   rating_of_photo      1007 non-null   float64\n 5   interest_score       1007 non-null   float64\n 6   device_type          1007 non-null   object \n 7   time_of_day          1007 non-null   object \n 8   booked_info_session  1007 non-null   int64  \n 9   shared_email         1007 non-null   int64  \n 10  saved_photo          1007 non-null   int64  \ndtypes: float64(3), int64(5), object(3)\nmemory usage: 86.7+ KB\n\n\n\ncruise_pics.describe()\n\n\n    \n\n\n\n\n\n\nclicked\ntime_on_page\nnum_followup_clicks\nrating_of_photo\ninterest_score\nbooked_info_session\nshared_email\nsaved_photo\n\n\n\n\ncount\n1007.000000\n1007.000000\n1007.000000\n1007.000000\n1007.000000\n1007.000000\n1007.000000\n1007.000000\n\n\nmean\n0.156902\n23.081132\n0.233366\n7.432969\n7.805005\n0.083416\n0.060576\n0.103277\n\n\nstd\n0.363889\n23.576640\n0.781342\n1.087268\n3.530199\n0.276648\n0.238669\n0.304472\n\n\nmin\n0.000000\n0.500000\n0.000000\n4.200000\n3.670000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n12.300000\n0.000000\n6.700000\n5.870000\n0.000000\n0.000000\n0.000000\n\n\n50%\n0.000000\n15.700000\n0.000000\n7.500000\n6.630000\n0.000000\n0.000000\n0.000000\n\n\n75%\n0.000000\n20.100000\n0.000000\n8.200000\n7.445000\n0.000000\n0.000000\n0.000000\n\n\nmax\n1.000000\n120.100000\n6.000000\n10.600000\n22.630000\n1.000000\n1.000000\n1.000000\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\nWe have an impossible value in the rating_of_photo variable as the rating scale is 1 to 10 and we have a max value of 10.6. So we will consider that as a data entry error and change it to 10. Also, 22.63 interest_score is an outlier and can violate statistical test assumptions so that row will be removed.\n\ncruise_pics['rating_of_photo'] = cruise_pics['rating_of_photo'].replace(10.6, 10)\n\n\ncruise_pics = cruise_pics[cruise_pics['interest_score']&lt;= 15.00]\n\n\ncruise_pics['interest_score'].describe()\n\n\n\n\n\n\n\n\ninterest_score\n\n\n\n\ncount\n920.000000\n\n\nmean\n6.884424\n\n\nstd\n1.895969\n\n\nmin\n3.670000\n\n\n25%\n5.817500\n\n\n50%\n6.500000\n\n\n75%\n7.200000\n\n\nmax\n14.780000\n\n\n\n\ndtype: float64\n\n\nExploring average interest_score by each cruise photo\n\ninterest_score_means = cruise_pics.groupby('photo')['interest_score'].mean().round(2).sort_values(ascending = False)\n\n\nplt.figure(figsize=(8, 6))\ninterest_score_means.plot(x = 'photo', y = 'interest_score', kind = 'bar', color = 'orange')\nplt.title('Average interest score per cruise photo')\nplt.xlabel('Cruise pics name')\nplt.ylabel('Average interest score per visit')\nplt.xticks(rotation = 0)\nplt.show()\n\n\n\n\n\n\n\n\nTropical beach here leads the race in terms of the interest_score which can proxy to engagement or consideration phase with the marketing efforts of the brand, however it is evident that the other tree cruise pics do not lag behind by a huge margin. Hence we need to perform statistical test to determine if this difference is truly significant and if so then we can evaluate which cruise pic drives the highest engagement.\nWith this data, we have two critical metrics that represent a consideration/engagement phase and booked_info_session that represents the conversion phase of the marketing funnel. So in order to make the business decision we can run two statistical tests to compare the cruise pics against interest_score and booked_info_session.\nPerforming 1-tailed t-test between night glow and carribean_port.\nWe are performing t-tests 6 times which means the chances of Type 1 error which is misclassification increases so we incorporate Bonferroni correction to adjust the alpha threshold\n\nadjusted_alpha = 0.05 / 6\nadjusted_alpha\n\n0.008333333333333333\n\n\nNull hypothesis (H0): The interest_score of night glow is less than or equal to the carribean port.\nAlternate hypothesis (H1): The interest score of night glow is greater than the carribean port.\n\nfrom scipy import stats\n\nnight_glow = cruise_pics[cruise_pics['photo'] == 'Night Glow']['interest_score']\ncaribbean_port = cruise_pics[cruise_pics['photo'] == 'Caribbean Port']['interest_score']\ncity_visit = cruise_pics[cruise_pics['photo'] == 'City Visit']['interest_score']\ntropical_beach = cruise_pics[cruise_pics['photo'] == 'Tropical Beach']['interest_score']\n\n\nt_stat, p_value = stats.ttest_ind(night_glow, caribbean_port, alternative='greater')\n\nprint(\"T-statistic:\", t_stat)\nprint(\"One-tailed p-value:\", p_value)\n\nT-statistic: -8.939846351868479\nOne-tailed p-value: 1.0\n\n\nWe failed to reject the null hypothesis as the result is not significant and even T-statistic is negative which means the interest_score of night glow is higher however that result is not significant and can be attributed to random chance.\nPerforming a 1-tailed T-test between Night glow and city visit\nNull hypothesis (H0): The interest_score of night glow is less than or equal to the city visit\nAlternate hypothesis (H1): The interest score of night glow is greater than the city visit.\n\nt_stat, p_value = stats.ttest_ind(night_glow, city_visit, alternative='greater')\n\nprint(\"T-statistic:\", t_stat)\nprint(\"One-tailed p-value:\", p_value)\n\nT-statistic: 10.611450287344818\nOne-tailed p-value: 5.274956225341654e-24\n\n\nFor this test we can reject the null hypothesis and conclude that interest_score of night glow is greater than the city visit and the test is significant as p-value is way below alpha threshold.\nPerforming a 1-tailed T-test between Night glow and tropical beach\nNull hypothesis (H0): The interest_score of night glow is less than or equal to the tropical beach\nAlternate hypothesis (H1): The interest score of night glow is greater than the city visit.\n\nt_stat, p_value = stats.ttest_ind(night_glow, tropical_beach, alternative='greater')\n\nprint(\"T-statistic:\", t_stat)\nprint(\"One-tailed p-value:\", p_value)\n\nT-statistic: -2.555744016689126\nOne-tailed p-value: 0.9945340059622229\n\n\nWe failed to reject the null hypothesis as the result is not significant and even T-statistic is negative which means the interest_score of night glow is higher however that result is not significant and can be attributed to random chance.\nPerforming a 1-tailed T-test between Caribbean port and City visit\nNull hypothesis (H0): The interest_score of Caribbean port is less than or equal to the City visit\nAlternate hypothesis (H1): The interest score of Caribbean port is greater than the City visit.\n\nt_stat, p_value = stats.ttest_ind(caribbean_port, city_visit, alternative='greater')\n\nprint(\"T-statistic:\", t_stat)\nprint(\"One-tailed p-value:\", p_value)\n\nT-statistic: 13.982424247119607\nOne-tailed p-value: 8.877001635568374e-38\n\n\nWe can reject Null hypothesis here as the p-value is much lower than the alpha threshold and the difference of interest_score is also high between Caribbean port and city visit.\nPerforming a 1-tailed T-test between Caribbean port and Tropical beach\nNull hypothesis (H0): The interest_score of Caribbean port is less than or equal to the Tropical beach\nAlternate hypothesis (H1): The interest score of Caribbean port is greater than the Tropical beach.\n\nt_stat, p_value = stats.ttest_ind(caribbean_port, tropical_beach, alternative='greater')\n\nprint(\"T-statistic:\", t_stat)\nprint(\"One-tailed p-value:\", p_value)\n\nT-statistic: 6.7791237990506925\nOne-tailed p-value: 1.8994641599563492e-11\n\n\nHere we fail to reject null hypothesis as the p-value is greater than alpha threshold and the difference is almost 0.\nPerforming a 1-tailed T-test between City visit and Tropical beach\nNull hypothesis (H0): The interest_score of City visit is less than or equal to the Tropical beach\nAlternate hypothesis (H1): The interest score of City visit port is greater than the Tropical beach.\n\nt_stat, p_value = stats.ttest_ind(city_visit, tropical_beach, alternative='greater')\n\nprint(\"T-statistic:\", t_stat)\nprint(\"One-tailed p-value:\", p_value)\n\nT-statistic: -11.162597925106882\nOne-tailed p-value: 1.0\n\n\nSame case here as well, the test fails to reject null hypothesis because of high p-value and also the difference is in the opposite direction.\nExplanation: Our purpose is to identify which of the cruise pics have the highest interest score and if that is a significant result and not just because of random chance. So we first calculate the avg interest score using the data and get this flow - Tropical beach &gt; Caribbean port &gt; Night glow &gt; City visit. However, we need to be sure that this is a meaningful difference. Since t-test are sensitive to outliers we reduce the variation in the interest score by removing outliers higher than 15 so that we can get stable stats. However we can see that only significant test we are able to conclude is that Night glow has higher interest score than city visit and Caribbean port is greater than city visit but the comparison between the two Caribbean and night glow does not generate significant results and even the difference is in opposite direction i.e Carribean port has higher interest score than night glow but that result appears more by random chance. So in the engagement phase we are not able to differentiate between the cruise pics.\nCalculating booking sessions by each cruise picture.\n\nbooking_rates = cruise_pics.groupby('photo')['booked_info_session'].count().sort_values(ascending=False)\n\nprint(booking_rates)\n\nphoto\nCaribbean Port    252\nNight Glow        240\nCity Visit        227\nTropical Beach    201\nName: booked_info_session, dtype: int64\n\n\n\nplt.figure(figsize=(8, 6))\nbooking_rates.plot(x = 'photo', y = 'booked_info_session', kind = 'bar', color = 'royalblue')\nplt.title('Booked info sessions by each cruise photo')\nplt.xlabel('Cruise pics name')\nplt.ylabel('Count of booked info sessions')\nplt.xticks(rotation = 0)\nplt.show()\n\n\n\n\n\n\n\n\nPerforming chi-square of independence to check if the cruise pic affects photo bookings.\nNull Hypothesis (H0): The cruise photo has no effect on the number of info session bookings.\nAlternate Hypothesis (H1): The cruise photo has an effect on the number of info session bookings.\n\ncontingency_table = pd.crosstab(cruise_pics['photo'], cruise_pics['booked_info_session'])\n\nchi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n\nprint(\"Chi-square statistic:\", chi2)\nprint(\"P-value:\", p_value)\nprint(\"Degrees of freedom:\", dof)\n\nChi-square statistic: 5.940401911123831\nP-value: 0.1145460790212076\nDegrees of freedom: 3\n\n\nAs we move to the conversion phase where we look at info session bookings, this can be considered as the conversion phase. For this we have the calculated number of bookings that can be attributed to each cruise picture. Since count is solely based on recorded observations, there are no possibilities of random occurence of these values. However, we need to evaluate that the cruise pic actually impacts the number of info session bookings. For this we use the Chi-square goodness of fit test and then conclude if we can use the above calculated counts to conclude which cruise pic is more beneficial from a marketing perspective. After performing the chi-test we can see that the photo does not impact info session bookings and the result is not significant as we have p value lower than 0.05 and also the chi-square statistic indicates that the difference between observed and expected values is large enough, however the difference is due to random chance, so in that case we cannot clearly conclude that the cruise photo impacts the visitors decision to book an info session. With this we can make a decision on the data that in both interest_score and number of info sessions booked, Caribbean port records the highest number and since conversions are most important for the business we can rely on the observations here to some extent and recommend Caribbean port cruise picture to be used in marketing campaigns by Lobster land management\n\n\nConclusion\nAll of these findings give Lobster Land a strategic foundation for successfully launching a cruise business. By focusing on high-traffic markets such as the Eastern Caribbean and Bahamas, investing in upgraded ships and designing flexible, experience-oriented spaces such as Vela Nera, the company can maximize guest satisfaction and operational efficiency from the start. Passenger segmentation results, cancellation models and A/B marketing tests ensure that Lobster Land can not only attract the right travelers, but also anticipate their needs, minimize risk and build loyalty over time.\nTableau Results:* Lobster Land Management should prioritize using newer, large-capacity ships to maximize exposure to high-volume, modernized traffic while minimizing potential operational risks.\nSummary Stats Results:* Strong opportunities appear in the Eastern Caribbean and the Bahamas, especially at Major and Boutique ports, where both traffic and spending levels are high. These areas may offer the best return on investment for experiential offerings, pop-up activations, or new retail ventures.\nSegmentation Results:* Premium Experience Ports align most directly with business objective. Popular Tourist Ports serve as reliable volume-drivers, ideal for standard or high-capacity sailings. Niche Interest Ports, while less predictable in terms of margin, offer an opportunity for innovation, differentiation, and deeper engagement with specialized consumer audiences. Given these results, we believe Premium Experience Ports are the most optimized for Lobster Land‚Äôs profitability and operationability.\nClassification Results:* The cancellation prediction model offers valuable insights for Lobster Land management by identifying certain customer behaviors that are associated with a higher probability of canceling a cruise booking. The results of this classification model can and should be transformed into actionable strategies for both customer retention and operational planning. Passengers identified as high-risk of cancelling (those with unpaid balances, no loyalty status, or gift certificate usage) can be identified early in the booking lifecycle and prioritized for targeted outreach. Marketing teams can prepare automated follow-up emails, personalized confirmations or time-sensitive incentives to encourage payment completion or strengthen commitment to the booking.\nConjoint Analysis Results:* Based on guest preference ratings and cost optimization, the final recommended voyage experience includes a Maine Lobster and Nova Scotia Seafood Buffet, Jazz Blues live entertainment, Romantic Escape cabins, Top Deck Hot Tubs, and one free cocktail credit per passenger, totaling 72.5usd per guest and staying within the 75usd target budget. This combination prioritizes the most valued components‚Äîdining, amenities, entertainment, and cabins‚Äîwhile balancing guest satisfaction with operational costs. By aligning offerings with guest preferences and using trade-offs, customer experience is maximized and optimize onboard revenue, ensuring a strong market entry.\nForecasting Results:* The cruise industry had a restructure after Covid and hence historical data before that has minimum prediction ability to predict future signals.\nA/B Testing Results:* Conversion is the most important piece of the marketing funnel after all the efforts and for cruise industry the visual appeal creates a significant impact in either driving leads and converting them even though it maybe difficult to measure their significance in earlier stage of the funnel.\nStrategic memo:* To attract key demographics including retirees, families, and young professionals, Lobster Land will introduce a new short-cruise experience featuring Vela Nera, a glass-enclosed restaurant and bar that transforms into an aquatic show venue. This design caters to Portland‚Äôs weather by offering a year-round, captivating experience and strategically employs temporal layering to adapt the space throughout the day, ensuring each guest segment feels valued and creating memorable experiences."
  },
  {
    "objectID": "projects/project_microbrewery.html",
    "href": "projects/project_microbrewery.html",
    "title": "Microbrewery Strategic & Quality Control Analysis",
    "section": "",
    "text": "üç∫ Microbrewery Strategic & Quality Control Analysis\n\nOperations Optimization ‚Ä¢ Risk Modeling ‚Ä¢ Decision Analytics\nA comprehensive analytics project combining financial modeling, Monte Carlo simulation, decision trees, linear programming, and risk assessment to evaluate the feasibility and production strategy of launching a microbrewery in Houston, Texas.\n\n\n\n\n\nüìå Executive Summary\nThis project evaluates the launch strategy of a Houston-based microbrewery through a robust combination of quantitative modeling, risk simulation, and operational optimization.\nUsing data-driven decision frameworks, we assessed demand variability, defect rates, seasonal production cycles, and financial outcomes.\nKey analytical components include:\n\nMonte Carlo Simulation (1,000+ iterations) to evaluate risk and uncertainty in brewing output\n\nDecision Tree Analysis to analyze strategic production alternatives\n\nLinear Programming Optimization for production scheduling and ingredient allocation\n\nBreak-even and Profitability Modeling for investment feasibility\n\nHypergeometric Distribution for defect rate evaluation in microchip quality testing\n\nThis integrated approach resulted in a projected 15% ROI by Year 3, with enhanced visibility into risks, operational constraints, and market positioning.\n\n\n\n\nüîß Methods & Techniques\n\nSimulation & Risk\n\nMonte Carlo Simulation\n\nScenario Modeling\n\nHypergeometric Quality Control Tests\n\n\n\nOptimization\n\nLinear Programming (LP) for production planning\n\nConstraint-based scheduling\n\n\n\nFinancial Modeling\n\nBreak-even analysis\n\nRevenue projections\n\nCost modeling\n\n\n\nDecision Frameworks\n\nDecision Trees\n\nSensitivity Analysis\n\n\n\n\n\n\nüíº Business Impact\nThis analysis provided a clear assessment of:\n\nOptimal production volumes\n\nInventory control for seasonal demand\n\nMinimizing operational losses due to microchip defects\n\nInvestment feasibility for microbrewery launch\n\nRisk-adjusted financial planning\n\nThe combination of simulation, optimization, and forecasting led to a defensible, data-backed investment strategy for the microbrewery‚Äôs launch.\n\n\n\n\nüìé Project Files\nClick below to access the original project deliverables.\n\nüìä Main Presentation (PPTX)\nüì• Download Presentation\n\n\nüìù Report Part 1 (DOCX)\nüì• Download Report Part 1\n\n\nüìù Report Part 2 (DOCX)\nüì• Download Report Part 2\n\n\n\n\n\n‚¨Ö Back to Projects"
  },
  {
    "objectID": "projects/project_cruise.html",
    "href": "projects/project_cruise.html",
    "title": "Cruise Market Segmentation & Conjoint Analysis",
    "section": "",
    "text": "üåä Cruise Market Segmentation & Conjoint Analysis\n\nCustomer Insights ‚Ä¢ Preference Modeling ‚Ä¢ Strategic Targeting\nA full analytical study combining K-means clustering, conjoint analysis, and behavioral segmentation to optimize product positioning and marketing strategy for the Caribbean cruise market.\n\n\n\n\n\nüìå Executive Summary\nThis project analyzes customer behavior, preferences, and value drivers within the Caribbean cruise industry.\nUsing marketing analytics and machine learning techniques, we segmented passengers, identified high-value clusters, and evaluated consumer preferences for cruise amenities and voyage features.\nThe analysis enabled:\n\nIdentification of distinct customer personas\n\nPrioritization of high-margin voyage features\n\nMeasurement of customer value through conjoint utilities\n\nInsights for optimizing pricing, promotions, and product design\n\nThis is a strong example of applying data science to real-world marketing strategy.\n\n\n\n\nüîß Methods & Techniques\n\nClustering & Segmentation\n\nK-means clustering\n\nPCA dimensionality reduction\n\nBehavioral grouping\n\nPattern recognition across voyage attributes\n\n\n\nConjoint Analysis\n\nUtility scoring\n\nPreference estimation\n\nAttribute importance ranking\n\nMarket choice simulation\n\n\n\nA/B Test Framework\n\nComparative variant testing\n\nConversion uplift measurement\n\nFeature prioritization\n\n\n\nSupporting Analytics\n\nExploratory data analysis (EDA)\n\nVisualization & insight narrative\n\nMarket segmentation logic\n\n\n\n\n\n\nüë• Segment Profiles\nBased on analysis, the cruise market was segmented into strategic personas:\n\n1. Value-Focused Travelers\n\nPrice sensitive\n\nPrefer shorter voyages\n\nBudget cabins, essential amenities\n\n\n\n2. Premium Leisure Seekers\n\nMid-to-high willingness to pay\n\nPrefer upgraded rooms & premium dining\n\nRespond well to bundled packages\n\n\n\n3. Experience Maximizers\n\nPrioritize premium excursions\n\nSeek longer voyages\n\nHigh relevance for luxury add-ons\n\n\n\n4. Family & Multi-Guest Groups\n\nNeed multi-room accommodations\n\nValue convenience features\n\nRespond to child-friendly amenities\n\nThese personas form the basis for targeted marketing and product differentiation.\n\n\n\n\n\nüíº Business Impact\nThe project provided actionable recommendations for:\n\nPricing strategy based on willingness-to-pay\n\nVoyage design optimized for segment preferences\n\nPromotional targeting for high-margin customer groups\n\nProduct bundling aligned with attribute utilities\n\nUpsell pathways that improve revenue per guest\n\nThese insights can significantly improve booking conversions, customer satisfaction, and long-term profitability.\n\n\n\n\nüìé Project File\nDownload the full Cruise Segmentation & Conjoint Analysis project below:\nüì• Download Cruise Project (PDF)\n\n\n\n\n‚¨Ö Back to Projects"
  },
  {
    "objectID": "projects/project_airbnb.html",
    "href": "projects/project_airbnb.html",
    "title": "Airbnb Market Pricing & Predictive Modeling",
    "section": "",
    "text": "üè° Airbnb Market Pricing & Predictive Modeling\n\nMachine Learning ‚Ä¢ Regression ‚Ä¢ Clustering ‚Ä¢ Geospatial Analytics\nA full statistical and machine learning analysis of the Airbnb market in Copenhagen, identifying key drivers of price, segmenting listings, and predicting price behavior using supervised and unsupervised learning methods.\n\n\n\n\n\nüìå Executive Summary\nThis project analyzes Airbnb listing data from Copenhagen using a blend of predictive modeling, clustering, and classification methods.\nThe primary goals were to:\n\nIdentify key price drivers\n\nBuild a predictive regression model\n\nSegment listings using PCA + K-Means\n\nClassify property types using Na√Øve Bayes, KNN, and Decision Trees\n\nProvide data-driven recommendations for hosts and investors\n\nThe final regression model achieved an Adjusted R¬≤ of 0.572, indicating strong explanatory power relative to typical real-estate datasets.\n\n\n\n\nüîß Methods & Techniques\n\nPredictive Modeling\n\nMultiple Linear Regression\n\nFeature Selection\n\nMulticollinearity Analysis\n\nResidual Diagnostics\n\n\n\nClustering & Segmentation\n\nPCA dimensionality reduction\n\nK-Means Clustering\n\nCluster profiling & heatmaps\n\n\n\nClassification Models\n\nNa√Øve Bayes\n\nK-Nearest Neighbors (KNN)\n\nDecision Tree Classifier\n\nConfusion matrix & accuracy evaluation\n\n\n\nGeospatial Analysis\n\nMapping price distribution across Copenhagen\n\nIdentifying high-value geographic clusters\n\n\n\n\n\n\nüîç Key Insights\n\nüè∑Ô∏è 1. Price Drivers Identified\nThe strongest predictors of price included:\n- Room type\n- Number of guests\n- Location coordinates\n- Host rating\n- Cleaning fee\n- Property size\n\n\nüß© 2. Clustered Listing Profiles\nUsing PCA + K-Means, three main clusters emerged:\n- Budget Listings ‚Äì small units, lower review scores\n- Standard Listings ‚Äì mid-tier price & amenities\n- Premium Listings ‚Äì large accommodations, strong ratings\n\n\nüéØ 3. Classification Accuracy\nAmong classification methods tested, Decision Tree achieved the best balance of accuracy and interpretability.\n\n\nüí° 4. Business Recommendations\n\nHosts can optimize revenue by adjusting price in line with identified predictors\n\nInvestors can target neighborhoods with highest value-to-cost ratio\n\nAirbnb could implement cluster-based recommendation engines\n\n\n\n\n\n\nüìé Project Files\n\nüìÑ Full Report (PDF)\nüì• Download PDF\n\n\nüåê HTML Report (Interactive)\nüì• Open HTML Version\n\n\n\n\n\n‚¨Ö Back to Projects"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "üì¨ Get in Touch\nIf you‚Äôd like to connect, collaborate, or learn more about my work, feel free to reach out.\nI‚Äôm always open to discussing data analytics, machine learning, business strategy, or project opportunities.\n\n\nüìß Email\nhungtrung.nguyen95@gmail.com\n\n\n\nüîó LinkedIn\nConnect with me on LinkedIn\n\n\n\nüíº GitHub\nVisit My GitHub Profile\n\n\n\nüìç Location\nBoston, MA"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hi, I‚Äôm Leo Hung Nguyen\nI‚Äôm a graduate student in Applied Business Analytics at Boston University, specializing in predictive modeling, data engineering, machine learning, and analytical strategy. My work focuses on transforming messy, complex datasets into insights that enable better decision-making and measurable business impact.\nI‚Äôm also a Teaching Assistant for AD599: Python & SQL for Business Analytics, where I support 70+ graduate students in mastering Python scripting, SQL querying, analytical workflows, and problem-solving techniques. This role has strengthened my communication, technical depth, and ability to guide others through complex analytical challenges.\n\n\nProfessional Background\nI bring hands-on experience across data analytics, financial modeling, marketing strategy, and international business development, along with strong problem-solving capabilities developed across multiple industries.\n\nDigital Marketing Director ‚Äì Tin A Co., Ltd (HCMC, Vietnam)\nI led data-driven marketing and international trade strategies across renewable energy, healthcare tech, automotive, and food sectors.\n- Improved targeting accuracy through segmentation\n- Managed 7+ monthly import/export operations\n- Secured partnerships across Asia, Australia & North America\n\n\nData Analyst ‚Äì Marriott Bonvoy Renaissance Riverside (Finance Department)\nI conducted cost modeling, automated financial reporting, and improved audit accuracy through analytics.\n- Reduced reporting errors\n- Automated 10+ workflows\n- Supported revenue optimization initiatives\n\n\nMarketing & Project Development ‚Äì Thang Uy Group\nI performed market research, investor outreach, and partnership alignment for EV infrastructure development across Singapore, Korea, Israel, and Vietnam.\n\n\n\nInterests & Focus\n\nPredictive Modeling & Machine Learning\n\nSQL Pipelines & ETL Automation\n\nBusiness Intelligence & Visualization\n\nOperations & Financial Analytics\n\nMarket Analysis & Strategy\n\nCloud Technologies & Scalable Analytics\n\n\n\nPersonal Side\nOutside of analytics, I enjoy exploring food spots, traveling, creating mechanical keyboards, watching basketball, and discovering ideas at the intersection of strategy, business, and technology."
  }
]